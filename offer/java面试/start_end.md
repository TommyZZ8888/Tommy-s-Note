### 自我介绍

面试官您好，我是张卫刚

我之前在君度科技有限公司担任java开发工程师的角色，期间主要负责政务方面纪检监督平台的核心模块开发工作。

在技术栈方面，我对Java语言有较深的认识，掌握其核心特性和并发编程模型。此外，我也熟练使用Spring、SpringBoot和MyBatisPlus等主流框架。数据库方面，我熟悉MySQL数据库的设计与优化；对于数据缓存Redis和消息队列kafka，我也有一定的实战经验。

这就是我的自我介绍，谢谢！



```
离职原因：
第一段： 疫情 加上 家里有些事，顺便休息一段时间
第二段： 公司趋向大多采用.net处理业务，java业务量少，功能零碎
第三段： 出差周期长
```



```
面试官您好，我是xxx

我之前在xxx公司担任java开发工程师的角色，期间主要负责xxx的核心模块开发工作，包括支付渠道的选择与路由、支付收银台界面设计以及支付风险控制系统的搭建。在此过程中，我积累了对接和维护支付宝、微信支付及银联支付等多种支付接口的经验，并对常见的支付逻辑和系统解决方案有了深入理解。

在技术栈方面，我对Java语言有较深的认识，掌握其核心特性和并发编程模型，并具备JVM调优的实际经验。此外，我也熟练使用Spring、SpringBoot和MyBatis等主流框架，能够快速搭建稳定的服务端应用。数据库方面，我熟悉MySQL数据库的设计与优化；而对于分布式系统中的数据缓存和消息队列，我也有一定的实战经验，尤其是kafka和Redis的应用。

在团队协作上，我认为沟通至关重要。曾负责多个跨部门项目的推进，深知团队内部及跨团队有效沟通的重要性。通过良好的沟通机制，不仅能够确保项目顺利进行，还能促进团队成员间的相互理解和信任。

面对技术挑战时，我喜欢从不同的角度审视问题，并寻找最优解。例如，在应对支付高峰期带来的系统压力时，我引入了异步处理机制，成功缓解了服务器负载，保证了支付流程的顺畅。

这就是我的自我介绍，谢谢！
```



### redis

##### redis是什么？

redis是一种基于key-value存储的非关系型数据库；

支持多种数据结构 string（token，计数），hash（用户信息），list（列表），set（共同关注），zset（排行榜）

基于内存，而且是单线程，避免了线程切换，所以读写速度非常出色

redis还提供了键过期，事务（multi开启事务，exec执行），lua脚本等功能

redis还提供了将内存中的数据利用快照或日志保存到磁盘，防止断电后数据丢失



##### redis多路复用

以epoll为例：

将用户socket对应的id都注册到epoll中，然后epoll监听哪个socket上有消息到达，然后就处理哪个，充分利用资源



##### 持久化

rdb 和 aof

rdb：redis data base 是把当前进程中的数据生成快照存放到硬盘，以便重启时恢复数据

两种方式：手动 自动；；手动触发分为save命令 阻塞当前服务器，直到rdb完成，对于比较大的实例，可能会阻塞较长时间

bgsave，fork个子进程，在子进程中完成rdb，阻塞只在fork的一瞬间。

自动触发：shutdown如果没有开启aof会触发 ， save m n m秒内修改n次触发；



rdb是一个紧凑的二进制文件，数据恢复速度快，但由于间隔一段时间持久化，所以可能会损失一段时间的数据。



aof（append only file），以独立日志的方式记录每次写命令，再次重启时重新执行命令以达到恢复数据的目的。

aof解决了数据持久化的实时性问题，但是文件较大，恢复数据速度慢。

流程：文件写入=》同步=》重写=》



选择：一般来说会选择混合的方式进行持久化，如果可以容忍一段时间数据的丢失，可以选择rdb

全量的rdb和增量的aof日志文件。



##### 高可用

主从复制，哨兵，集群

主从复制：数据冗余，故障恢复，负载均衡，高可用基石

一主一从；故障转移

一主多从：读写分离

问题：一旦主节点出现故障，需要手动将从节点升级为主节点



Redission实现分布式锁的原理？
1.使用lua脚本保证原子性
2.增加一个看门狗不断延长有效期
3.使用Redisson的公平锁和红锁来提供更公平的锁竞争机制



##### 哨兵

作用：监控，自动故障转移，配置提供者，通知

主观下线和客观下线：主观：每个sentinel每秒会向其他主节点，从节点，sentinel节点发送ping命令，如果超过规定的时间没有回复，则认为失败下线

客观：当下线的是主节点时，从节点会向其他从节点发送命令询问，如果多数从节点都判断主节点下线，那就做出客观下线的决定



故障转移流程：

1.选举出一个主节点

2.执行命令slaveof no one让其成为主节点

3.主节点向剩余的从节点发送命令，让其成为新主节点的从节点

4.将原来的主节点更新为从节点，待其故障恢复后，复制新的主节点



sentinel选举：每个在线的sentinel节点都有资格成为领导者，当他确定主节点下线时，会向其他sentinel节点发送命令，如果其他sentinel没有同意

其他sentinel节点，就不会拒绝，如果得到票数大于规定票数，那么他会成为领导者，否则进入下一次选举。



新节点：过滤不健康的节点（主观下线，断线），，选择从节点最高的从节点列表，存在返回不存在继续，，选择复制偏移量最大的从节点（数据最完整），，选择runid最小的从节点。



redis集群：解决高可用和分布式的问题

数据分区：节点取余分区，一致性hash分区，虚拟槽分区



##### 缓存

缓存击穿：key过期，直接访问数据库++++++++解决：加锁更新，把过期时间写进value，异步更新

缓存穿透：缓存数据库都不存在++++++++解决：缓存空值默认值；设置较短的过期时间，布隆过滤器

缓存雪崩：同一时间大量的key过期，全部访问数据库++++++++解决：均匀的设置过期时间，集群，热点数据永不过期88



缓存数据库一致性：

首先引入redis就是为了高可用，那根据cap原则，满足高可用，一致性就没法保证。所以只能满足最终一致性。

那怎么保证最终一致性，我认为先写数据库再删缓存，失败就起线程时间分级异步重试，这足以应对99%的问题了。

关于mq或者订阅binlog那种方式思路都是一样的，但是逻辑太重了，增加系统复杂度，看业务情况，有的会得不偿失。

那我接着讲下为啥删除缓存而不是更新缓存，，，至于为啥先写数据库再删缓存，，，我再讲下mq和binlog那套，，，



删除缓存还是更新缓存：删除缓存++删除缓存操作更快，redis以空间换时间，更新缓存可能一段时间用不到，造成一段时间的数据冗余

先更新数据库还是先删除缓存：先更新数据库++更新数据库的操作设计锁行锁表操作，几乎不可能在删除缓存之前完成

消息队列：更新数据库后，发送消息到消息队列，待消费消息成功后，删除缓存

canal+mq，使用阿里的数据库监听中间件监听binlog变化，一旦数据修改，canal会自动发送消息到消息队列



布隆过滤器：是一个连续的数据结构，每个存储位存储一个bit位存储0或1，判断key是否存在即判断是否全是1



本地缓存和分布式缓存的一致性问题：本地缓存Caffeine，分布式缓存redis，，可以使用redis的发布订阅，，也可以使用消息队列



缓存预热：

1.写个接口，上线后手动更新

2.数据量不大的情况下，项目启动时更新

3.定时刷新



热key问题：热key通常大量的访问，首先监控，每次调用redis，对key进行记录

也可以使用命令查看每个key的调用次数 monitor命令

监控到之后：把热key打散到不同的服务器，加入二级缓存，每次先从二级缓存查询



热key重建：开发的时候一般使用“缓存+过期时间”的策略，既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求

但是可能并发量大，涉及大量的计算，短时间重建不好

解决：1.互斥锁，只允许一个线程重建，，2.永不过期，对每个值设置一个过期值



无底洞问题：节点不断增加，性能反而下降

先分析一下无底洞问题：

- 客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增大。
- 网络连接数变多，对节点的性能也有一定影响。

常见的优化思路如下：

- 命令本身的优化，例如优化操作语句等。
- 减少网络通信次数。
- 降低接入成本，例如客户端使用长连/连接池、NIO等。



#####  redis运维

redis内存不足：修改配置文件的maxmemory，，集群部署

redis过期回收策略： 定时删除：创建key时，增加过期时间，，当过期key较多时，会占用大量的cpu

​									 惰性删除：查询key的时候进行检查，如果key一直没有被查询，那就永远不会删除

​									 定期删除：每隔一段时间对数据库做一次检查，删除过期的key，，由于不可能对所有的key做轮询，所以随机取一些key检查

redis使用惰性+定期：：先定期删除，由于随机取key，所以没有取到的key惰性删除



内存溢出/内存淘汰策略：

1. noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返 回客户端错误信息，此 时Redis只响应读操作。
2. volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直 到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。（常用）



redis阻塞：

​	api或数据结构不合理，slowlog get(n) 命令找到慢查询，	

1）修改为低算法复杂度的命令，如hgetall改为hmget等，禁用keys、sort等命 令

2）调整大对象：缩减大对象数据或把大对象拆分为多个小对象，防止一次命令操作过多的数据

cpu饱和，集群



大key问题：value值过大，hash list set存储过多元素  导致客户端耗时增加，io操作占用cpu，主动删除 被动删除阻塞

解决：bigkeys命令以遍历的方式分析redis中所有的key，并返回每种数据类型top1的key



可删除，使用unlink方式异步删除

不可删除，压缩和拆分



##### redis应用

异步队列：pubish/subscribe

实现延迟队列：使用zset，设置时间戳作为score排序，再通过zrangebyscore查询。



redis事务：提供简单的事务 multi开启事务，exec提交。不支持回滚，回滚会增加很多工作



redis+lua

lua脚本在redis中是原子性的，执行过程中不会插入其他指令。减少网络开销



redis 管道 pipeline

nc指令 节省了rtt（round trip time）将多条命令一起打包，减少了客户端服务端调用次数，减少了上下文切换



redis分布式锁

setnx指令：问题：如果del指令执行异常出错，那么key永远不会释放，，v2：加过期时间，如果expire指令执行异常，那也永远不会释放

原因setnx 和 del指令不是一个原子性的：：解决方案 redission



##### redisearch

创建索引：

```sql
FT.CREATE myIdx ON HASH PREFIX 1 doc: LANGUAGE chinese SCHEMA title TEXT WEIGHT 5.0 body TEXT url TEXT

```









### mysql

##### 1.mysql调优

1.参数优化：bufferpool内存，tablecache，，硬件优化：大的内存，多处理器

2.设计表的优化：数据库设计根据三大范式，适当增加一些冗余字段

3.逻辑查询优化： 在被驱动表上的join字段建立适当的索引，

使用join查询代替子查询，（因为子查询要建立一张临时表，执行效率不高）

使用覆盖索引

用小表查出来的数据驱动大表查询

尽量不使用select *，使用具体字段

count(*)=count(1)>count(字段)

4.主从复制，读写分离



##### 2.避免索引失效：

1.不使用or（or前后存在非索引字段，索引失效）

2.like模糊查询 百分号查询后面

3.使用isnull，不使用isnotnull，<>

4.不在索引字段上做计算或函数操作

5.联合索引遵循最左匹配原则

6.不在索引列做类型转换

7.范围查询，右边的列索引失效（使用索引下推）



##### 3.mysql执行流程

查询请求== 客户端建立连接==》 查询缓存 ==》 词法语法解析器 ==》查询优化器 ==》 执行器 ==》返回结果



##### 4.mysql事务

事务就是一组逻辑操作单元，使数据从一种状态到另一种状态，要么所有的事务都被提交，这些修改被永久保存下来，要么全部失败，回滚到操作之前的状态。

事务的acid特性

Atomicity 原子性：事务是一个不可分割的原子操作，要么全部成功，要么全部失败，不允许中间状态 ==》undolog保证

Consisetency 一致性： 事务执行前后，数据从一个合法的状态到另一个合法的状态，数据库的数据要符合现实世界的约束，例如：银行存款不能为负数

Isolation: 隔离性： 一个事务的操作不受其他事务操作干扰，多个事务操作之间不相互影响，由mvcc和锁保证

Duration： 持久性: 事务一旦执行成功，数据的改变是永久的，由redolog保证



事务的并发问题：脏写，脏读，不可重复度，幻读

脏写：事务a修改了未提交的事务b的修改的数据，之后事务b回滚，事务a的修改失效

脏读：事务a读取了未提交事务b更新过的数据，之后事务b回滚，事务a读取的只是一个临时数据

不可重复读：事务a读取一个字段未提交事务，之后事务b修改了该字段并提交事务，事务a再次读取，两次读取字段值不同

幻读：事务a读取了一个字段为null的数据，未提交事务，之后事务b在该字段插入了一行数据并提交事务，事务a再次读取同一字段，发现有数据了



事务的四大隔离级别：读未提交，读已提交，可重复度，串行化

读未提交：所有事务都可以看到未提交事务的数据，不可避免脏读，幻读，不可重复读

读已提交：一个事务只能看到其他事务提交的结果。可以避免脏读，不可避免不可重复读，幻读

可重复读：一个事务读取一条数据之后，事务b修改并提交，事务a再次读取结果不变，可以避免不可重复读，默认的隔离级别

可串行化：在事务读取一个相同的行，事务执行期间，不允许其他事务对该表进行增删改操作，可避免幻读，但效率低下



##### 5.mysql事务日志

redolog和undolog

**redolog**：重做日志，可以保证事务的持久性。

在传统情况下，事务对数据修改之后，会把该数据放到缓冲池中，事务提交之后，如果数据库宕机了，数据未被刷新到磁盘上，数据就会丢失。

解决方式：

1.事务提交之前就把所有已修改的数据刷新到磁盘上：

问题1：innodb是以页为基本单位读写数据的，如果只修改一个字节的数据，就刷新到磁盘上，会增加磁盘io的时间，服务器效率会降低

问题2：一个修改操作可能会涉及多个数据页，这些数据页可能不是连续的，将缓冲池中的数据刷新到磁盘上可能就需要多次随机磁盘io。随机io比顺序io效率低

2.使用redolog记录事务的操作

我们只要在把每个事务的操作记录下来，数据库宕机后，直接使用redolog文件重新执行就可以了。

一个事务中的操作可能会产生多条redolog，redolog是物理日志，某个数据页某个数据的偏移量。

redolog的使用降低了刷盘频率，而且redolog占用的空间很小，因为他只记录存储空间表id，页号，主键值，偏移量

在事务执行过程中，是不断记录redolog的，binlog只有在事务提交，数据才会被记录，所以日志是按顺序被写入的，也按顺序刷新到磁盘，是顺序io。



redolog分为两部分：redolog buffer，redolog file

redolog buffer保存在内存中，redolog file保存在磁盘上

redolog的执行过程：

例如一个更新操作：

读取数据到bufferpool中  ==》 修改数据，redolog记录修改后的值 ==》事务提交时，将bufferpool中的内容刷盘到redolog buffer中，采用的追加写的方式写入redologbuffer ==》 定期将内存修改后的数据刷新到redolog file 。当数据库发生宕机，使用redolog恢复



redolog的刷盘：

redolog是由innodb先写入redolog buffer，然后按照刷盘策略刷入redolog file。

**redolog刷盘到redologfile中的过程并不是真正写入磁盘，只是写到文件系统缓存pagecache中，真正的刷盘到relogfile由系统决定**

三种刷盘策略：0 每隔1s，将redologbuffer数据写入日志文件，并将文件写入磁盘，效率最高，但一旦宕机，会丢失1s的数据，违反持久性

1.每次提交事务，再将数据写入日志文件，并将文件写入磁盘，最安全，但效率低，默认

2.每次提交事务时，写入文件，间隔1s将数据将文件写入磁盘，比0安全，但也会丢失1s的数据



追加写入redologbuffer

例如一个圆：一个点是checkpoint，记录刷盘到redolog file的位置，一个点writepos，记录写入redologbuffer的位置，两者之间可以记录redolog

一旦两者位置相同，不可写入，先将redologbuffer中日志写入日志文件中，checkpoint会后移，才会继续写入redolog



**undolog**

undolog会保证事务的原子性

当事务执行到一半，系统宕机后，当手动输入rollback情况下，需要undolog进行回滚操作，使数据看起来是执行事务之前的状态

只有增删改操作会记录undolog，查询操作不会。

undolog是逻辑日志：当执行一条新增操作，系统至少会记录新增的主键值，回滚时，直接将该主键对应的数据删除即可（对每个insert，innodb回滚时，会执行一条delete操作）

当执行一条删除操作，会记录删除前的数据，回滚时，innodb会执行一条新增操作



undolog分为两种类型：

insert undolog：对于插入操作，会记录一条insert undolog，提交事务后，会删除该undolog

update undolog： 对于删除和更新操作，会记录update undolog，事务提交后，不会删除，因为可以mvcc需要，会放入undolog版本链



undolog有两种回滚操作和mvcc

1.回滚：将数据恢复到事务执行前的样子，但并不是和事务执行前状态存在差异。

2.mvcc：mvcc是依靠undolog实现的。当读取一条记录，若该记录被正在执行的事务占用，当前事务可以通过undolog版本链找到之前已经提交事务的版本，以此实现非锁定读。



##### 6.mvcc 多版本并发控制

mvcc主要保证了事务的隔离性，实现了数据的一致性读，实现依赖于undolog和readview

undolog和隐藏字段（trx_id，rollpoint）实现了多版本

readview实现了并发控制

数据的读取分为两种：快照读和当前读

快照读：又叫做一致性读，读取的是数据的历史版本，不加锁的select是快照读

mvcc的也是基于快照读，在很多情况下，避免了加锁操作，降低了开销，提高了数据库的并发性能

当前读：读取的是数据的最新版本，加锁的select，增删改操作都会进行当前读

当前读基于锁，读取记录时，其他事务不可增删改操作



刚讲了两个隐藏字段：

trx_id：每次一个事务对某条聚簇索引修改时，都会把该事务的事务id赋值给当前记录的trx_id

rollpoint：每次对数据进行修改，都会把历史版本记录到undolog版本链，rollpoint相当于一个指针，可以通过它找到修改前的版本数据



readview：

事务在使用mvcc进行快照读时产生的读视图，只会在读已提交和可重复读隔离级别下使用

readview：creator_id, trx_ids, min_id, max_id

creator_id: 开启当前事务的事务id

trx_ids: 生成readview时当前系统活跃着的事务id列表

min_id: 活跃着的事务列表中的最小值

max_id：并不是活跃着的事务id列表中的最大值，是系统应该分配给下一个事务的id值



readview的规则：

当访问某条记录时，生成一个readview

若当前记录的trx_id等于readview的creator_id，当前事务在访问自己修改的记录，所以当前版本可以被读取

若当前记录的trx_id小于min_id，表明当前事务读取的是之前已经提交事务的版本，可以被读取

若当前记录的trx_id大于或等于max——id，表明当前事务读取的是生成该readview之后才开启的事务，不可读

若当前记录的trx_id在trx_ids列表中，表明生成该readview时该版本的事务还是活跃的，不可读

若不在列表中，则表示创建readview时，该版本事务已提交，可读



readview生成时机

在读已提交级别下：一个事务中每个读操作都会生成一个readview，所以两个相同的读操作，生成的readview不同

在可重复读级别下：一个事务中的读操作只会第一次读时生成一个readview，其他读操作复用这个readview



mvcc整体流程：

查询一条数据

1.获取事务本身的版本号，也就是该事务id

2.获取该事务的readview

3.获取读取记录的事务id，然后和readview的规则进行比较

4.如果不符合规则，则从undolog版本链中获取下一个版本的数据

5.最后返回符合规则的数据





##### 7.锁

锁也是实现事务隔离性的一个方式，也是解决并发事务脏读幻读不可重复读的一种方案。

刚才讲过的当前读的实现就是基于加锁实现。

按类型：读锁（共享锁），写锁（排他锁）

按粒度：行锁，页锁，表锁

加锁方式lock in share mode， for update

对读取记录加读锁，其他事务可读，不可增删改操作

对读取记录加写锁，其他事务既不可读也不可写

当对数据进行dml语句增删改时，，会对该记录加排它锁



表锁：

表读锁和表写锁

意向锁：意向锁不由我们控制，系统控制；当对一条记录进行修改操作时，会自动为这条记录所在的表加上意向排他锁。该意向锁会告诉其他事务，该表中有记录被加上排他锁了。

现有两个事务，A,B，如果B想要在表上加共享锁或排它锁，如果A没有生成意向锁，会对表中每一行检查是否已经存在锁，如果A生成意向锁，只要检查该意向锁是否和表级共享或排它锁是否兼容即可。意向锁之间相互兼容，意向共享锁与共享锁兼容。

元数据锁：在对某个表执行alter table，drop table时，其他事务对表进行增删改查dml语句会阻塞，相反，对某张表进行dml语句时，会阻塞ddl语句。server层的锁。

当执行crud时，会加mdl读锁，当执行ddl语句时，会加dml写锁。

读锁之间相互兼容。

问题：

| 事务a                 | 事务b                    | 事务c                 |
| --------------------- | ------------------------ | --------------------- |
| select *  （mdl读锁） |                          |                       |
|                       | alter table  （mdl写锁） |                       |
|                       |                          | select *  （mdl读锁） |



a加锁，b阻塞，c要等b释放才能执行，不然一直阻塞



行级锁：

记录锁; 共享性记录锁，排他性记录锁，仅仅对一条记录加锁，不影响其他数据

间隙锁：可以解决幻读问题。例如对读取id为5的记录，该记录不存在，无法加记录锁，就会读上一条id为3和下一条记录id为8的值之间加上间隙锁。其他事务不可以在这个间隙插入数据，会被阻塞。

两个不同的事务对同一条记录加共享或排它锁，不会有冲突，因为是保护该间隙不被插入值，

就会可能发生死锁。

| 事务a                                     | 事务b                           |
| ----------------------------------------- | ------------------------------- |
| select* where id = 5 for upadte           | select* where id = 5 for upadte |
|                                           | insert into * where id = 5      |
| insert into * where id = 5   报错deadlock |                                 |



临建锁：innodb默认的锁，会对该记录和间隙加锁，记录锁和间隙锁的结合，是前开后闭区间

对唯一索引等值查询，给不存在的记录加锁时，优化为间隙锁

对二级索引等值查询，向右遍历最后一个值不满足查询条件时，退化为间隙锁

（查询一个age为3的值此id为3，会对上一个id为1和下一个id为7的范围加锁，，为了防止在此间隙再插入一条age为3的记录，出现幻读）

索引上的范围查询(唯一索引)–会访问到不满足条件的第一个值为止。



==排查死锁==

```sql
SHOW ENGINE INNODB STATUS
```

在输出结果中查找"LATEST DETECTED DEADLOCK"部分，这里会显示最近发生的死锁详细信息。

```sql
-- 查看锁等待
SELECT * FROM performance_schema.events_waits_current 
WHERE EVENT_NAME LIKE '%lock%';

-- 查看死锁历史
SELECT * FROM performance_schema.events_statements_history;

-- 查看当前锁等待
SELECT * FROM information_schema.INNODB_TRX;
SELECT * FROM information_schema.INNODB_LOCKS;
SELECT * FROM information_schema.INNODB_LOCK_WAITS;
```









##### 8.B+树索引

索引：分为聚簇索引和非聚簇索引（二级索引），innodb每个索引都是一棵b+树

聚簇索引：非叶子节点存储页号和主键值，叶子节点存储的是完整的数据结构，也就是索引即数据，数据即索引。

叶子节点之间是以主键值大小顺序排列的双向链表，同一层的非叶子节点也是按照主键值大小排序的双向链表

页内的记录是按主键值大小排序的单向链表

优点：数据访问快，聚簇索引保存了完整的数据结构

缺点：插入速度依赖于插入顺序



非聚簇索引：非叶子节点存储索引列和页号，叶子节点存储主键值和索引列

索引二级索引的查找需要回表。先查出主键值，然后根据主键值，再一次聚簇索引



使用聚簇索引的查询效率高，但增删改效率很低

一张表只能有一个聚簇索引，可以有多个二级索引



B树存储的是完整的数据结构，索引B+树要矮壮一些，

B树查询可能要跨层，所以查询效率比B+树低





##### 9.主从复制

主从复制依赖于binlog和relaylog

binlog是二进制文件，主要用于数据恢复和数据复制，是serve层

binlog有三种刷盘时机：

1每次提交时写入文件缓存，fsync写入binlog刷盘由系统决定

2.每次提交写入文件缓存，并刷盘到binlog文件

3.每次提交写入文件缓存，多个事务之后写入binlog



存在问题：

binlog每次事务提交写入，redolog事务过程中不断写入。当redolog写入之后，binlog写入之前，mysql宕机了，binlog中并没有修改记录，主服务器用redolog恢复数据，从服务器用binlog恢复数据，会出现数据不一致的问题

解决：两阶段提交

将redolog写入redolog file过程分为两个阶段，准备阶段和提交阶段

事务过程中不断写入是准备阶段，事务提交且写入binlog后，redolog进入提交阶段，当用redolog恢复主服务器数据时，如果当前阶段是准备阶段，判断是否有binlog，有就进行提交事务，没有就回滚事务。



主从复制的作用：读写分离，数据备份，高可用性，原理就是从服务器从主服务器上读取binlog日志进行数据的同步

流程：当从库线程连接的时候，主库的**二进制转储线程**将二进制文件发送给从库  ==》 **从库的i/o线程**读取到主库的二进制转储线程发送的binlog更新部分，并且拷贝到本地的中继日志  ==》  最后**从库sql线程**读取从库中的中继日志，并且执行日志中的事件，将从库的数据与主库同步



问题：延迟，从库读取主库binlog日志，并执行完成日志事件所消耗的事件，，原因：从库的服务器性能差与主服务器，从库的压力大，大事务的执行

三种复制方案：

1.异步复制：客户端提交commit后，不需要等从库返回任何结果，而是直接将结果返回给客户端

2.半同步复制：客户端提交commit后，等至少一个从库接收到binlog，并且写入到中继日志，再返回给客户端，mysql5.5后采用这种方案

3.组复制：

```
在执行读写（RW）事务的时候，需要通过一致性协议层（Consensus 层）的同意，也就是读写事务想要进行提交，必须要经过组里“大多数人”（对应 Node 节点）的同意，大多数指的是同意的节点数量需要大于 （N/2+1），这样才可以进行提交`
`2、在只读（RO）事务，则不需要经过组内同意，直接COMMIT即可。
```



##### 10.一条sql删除重复数据保留一条

delete u1 from user u1 join user u2 on u1.name=u2.name where u1.id > u2.id

##### 11.快速复制一张表

insert into target_table select * from source_table

CREATE TABLE new_table AS
SELECT * FROM source_table



##### 12.sql语句的优化

所谓的`SQL`优化，就是指将一条`SQL`写的更加简洁，让`SQL`的执行速度更快，易读性与维护性更好。

1.查询时尽量不要使用*

2.连表查询时尽量不要关联太多表

3.多表查询时一定要以小驱大

4.不要使用like左模糊和全模糊查询

5.查询时尽量不要对字段做空值判断

6.不要在条件查询`=`前对字段做任何运算

7.!=、!<>、not in、not like、or...要慎用

8.必要情况下可以强制指定索引



##### 13. 行转列，列传行

参考：https://juejin.cn/post/7146492885708308487

**行转列：**

```sql
SELECT
	studentId as '学号',
	SUM( CASE course WHEN '语文' THEN score ELSE 0 END ) AS '语文',
	SUM( CASE course WHEN '数学' THEN score ELSE 0 END ) AS '数学',
	SUM( CASE course WHEN '英语' THEN score ELSE 0 END ) AS '英语',
	SUM( score ) AS '总分' 
FROM
	score 
GROUP BY
	studentId;
	
	SELECT
	studentId AS '学号',
	SUM( IF ( course = '语文', score, 0 ) ) AS '语文',
	SUM( IF ( course = '数学', score, 0 ) ) AS '数学',
	SUM( IF ( course = '英语', score, 0 ) ) AS '英语',
	SUM( score ) AS '总分' 
FROM
	score 
GROUP BY
	studentId;
```

列不确定：

```sql
SET @EE='';
select @EE :=CONCAT(@EE,'sum(if(subject= \'',subject,'\',score,0)) as ',subject, ',') AS aa FROM (SELECT DISTINCT subject FROM tb_score) A ;
SET @QQ = CONCAT('select ifnull(userid,\'TOTAL\')as userid,',@EE,' sum(score) as TOTAL from tb_score group by userid WITH ROLLUP');
-- SELECT @QQ;
PREPARE stmt FROM @QQ;
EXECUTE stmt;
DEALLOCATE PREPARE stmt;

```



**列转行：**

```sql
SELECT studentId,'语文' AS course,chineseScore AS score FROM score
UNION ALL
SELECT studentId,'数学' AS course,mathScore AS score FROM score
UNION ALL
SELECT studentId,'英语' AS course,englishScore AS score FROM score
ORDER BY studentId
```



### 微服务

##### 概念

什么是微服务：是一种软件架构风格，将一个大型服务拆分成一个个小型的，自洽且松耦合的服务，每个服务负责特定的业务功能，并通过轻量级通信机制通讯。

每个微服务都可以独立运行部署。增加了灵活性，可伸缩性，可扩展性。

单体化--》服务化--》微服务：单体服务过大--》soa--》微服务，，soa是一种设计原则，微服务可以看作是soa的一种实践。



 问题：系统复杂，服务间通信开销，团队沟通，数据一致性，部署运维复杂



解决方案：dubbo，spring cloud alibaba， spring cloud netflix。

组件：N：enreka consul，springcloud config，feign，zuul gateway hystrix  A：nacos，nacos config，gateway，sentinel，skywalking



##### 注册中心

作用：服务注册（启动时注册到注册中心），服务发现（客户端向注册中心查询可用的服务实例，客户端选择合适的实例进行调用），负载均衡，故障恢复，服务治理

eureka ap consul cp zookeeper cp nacos ap/cp

enreka原理：服务启动后，将实例注册到注册中心，消费者可以查询服务实例列表获取可用的服务实例

服务实例会定期向注册中心server发送心跳，以表示存活，如果一段时间没有接收到服务实例的心跳，将会标记为不可用，踢出服务列表，下线

负载均衡：enreka在调用其他服务时，会从本地缓存中获取服务的注册信息，本地缓存没有，向eureka发送查询请求，获取可用服务实例，通过负载均衡算法选择其中一个调用



保证高可用： 多实例部署：将enreka实例部署在多个节点上，

服务注册消息的复制：当一个服务实例向eureka server注册时，每个eureka server实例都会复制其他实例的注册信息，以保持数据一致性

自我保护机制：当eureka server 节点一段时间没有收到心跳，自动进入自我保护机制，不再剔除注册表中的服务实例，防止网络抖动或其他原因造成的误剔除。



##### 配置中心

作用：对不同环境，不同实例或者在动态运行时实例需要调整和管理

配置中心：springcloud config，nacos consul apollo zookeeper

nacos配置中心原理：配置信息存储--》注册配置信息--》获取配置信息--》监听配置变化

nacos配置中心长轮询机制：客户端发起pull请求，服务端检查配置有没有变更，如果没有，设置一个定时任务，在一段时间后执行，并将客户端加入等待队列。

在等待期间，一旦配置信息发生变更，立即返回结果给客户端，，如果在等待期间，配置没有发生变更，则达到超时时间返回结果给客户端



##### 远程调用

http是超文本传输协议，是应用层协议，主要强调网络通信；rpc是远程过程调用，是分布式系统之间通信的协议

基于http实现的远程调用是rpc的一种

比如feign的实现基于restTemplate（feign旧版使用restTemplate，Spring Cloud 2.x 开始可以选择使用okhttp）

feign基于http，dubbo基于rpc

**实现**：

首先通过@enablefeignclient注解开启feignclient的功能，只有这个注解存在，才会在程序启动时开启对@feignclient注解包的扫描。

根据feign的规则实现接口，并在接口上面加上feignclient的注解

程序启动后，会进行包扫描，扫描所有的@feignclient注解的类，并将这些信息注入到ioc容器中（当然会先扫描看有无@enablefeignclient注解，）

当接口的方法被调用时，通过jdk代理来生成具体的requestTemplate模板对象。

根据requestTemplate再生成http请求的request对象。

然后交给client去处理，client的网络请求框架可以是httpclient和OKhttp。

最后Client被封装到LoadBalanceClient类，这个类结合类Ribbon做到了负载均衡。



feign是一个声明式的web服务客户端，简化了使用基于http的远程服务的开发

feign第一次调用耗时很长：主要原因是ribbon的懒加载机制，发生第一次调用时，feign会触发ribbon的加载过程，（从注册中心获取服务列表，建立连接池等操作），增加首次调用耗时

feign实现认证传递：使用拦截器传递认证信息，可以通过实现Requestrceptor接口来定义拦截器，将认证信息加到请求头，然后注册到feign的配置中。

feign的负载均衡是通过集成ribbon实现的，ribbon通过从注册中心获取可用实例列表，并通过负载均衡算法选择合适的服务实例进行请求转发，实现负载均衡。

负载均衡的算法：

轮询：按照顺序将请求分配给后端服务器

加权轮询算法：在轮询的基础上加了权重的概念。

随机算法：随机分配

加权随机：

最少链接：根据后端服务器的连接数

hash算法：



##### 服务容灾

服务雪崩：一个或多个服务出现故障，如果这时候依赖的服务还是不断在请求，那么这些请求的压力会在下游不断堆积，进而导致下游服务负载增加，系统崩溃。

解决：服务高可用部署，限流或熔断，缓存或降级。

服务熔断：当某个服务出现异常或故障时，迅速隔离服务，后续请求返回默认值或错误信息，防止系统崩溃。

服务降级：也是微服务的一种容错机制，用于系统资源紧张或故障时保证核心功能。当系统出现异常时，主动屏蔽一些非核心功能，只提供最基本的功能，以保证系统稳定运行。



熔断降级方案：

hystrix，resilience4J，sentinel，dubbo

hystrix：@HystrixCommand(fallbackMethod = "fallbackMethod")

熔断：通过设置阈值来监控服务的错误率和超时时间，达到阈值熔断器将打开。

降级：当熔断器打开后，hystrix可以提供一个备用的降级方法或返回默认值，以保证系统稳定运行。



sentinel限流：

定义资源：资源可以是url，方法，用于标识需要进行限流的请求

配置限流规则：配置限流阈值，限流模式，资源名称

监控流量：监控每个资源的流量情况

限流控制：超过限流阈值，进行限制，拒绝，或进行其他降级处理。

采用的滑动窗口限流，滑动窗口限流算法是一种基于时间窗口的限流算法。它将一段时间划分为多个时间窗口，并在每个时间窗口内统计请求的数量。通过动态地调整时间窗口的大小和滑动步长，可以更精确地控制请求的通过速率。

Sentinel利用了Token Server和Token Client的机制来实现集群限流。

开启集群限流后，Client向Token Server发送请求，Token Server根据配置的规则决定是否限流



##### 服务网关

api网关：是一种中间层服务器，用于集中管理，保护，路由到后端服务器。充当客户端和后端服务之间的入口点，提供了一组统一的接口来管理和控制api的访问

功能：路由转发，负载均衡，认证与授权，监控与日志，api版本管理，缓存

zuul，gateway，Kong，

spring cloud gateway：

route（路由）：定义请求的匹配规则和转发目标，通过配置路由将请求映射到后端的服务实例或url上。

predicate（断言）：用于匹配请求的条件。如果请求满足断言的条件，则会应用所配置的过滤器。Spring Cloud Gateway提供了多种内置的断言，如Path（路径匹配）、Method（请求方法匹配）、Header（请求头匹配）等，同时也支持自定义断言。

filter（过滤器）：用于对请求进行处理和转换，可以修改请求，响应和执行自定义逻辑



##### 服务监控

prometheus和grafana

Prometheus：是一个开源的监控系统，可以通过http协议定期拉取微服务的·指标数据

grafana：是一个开源的可视化仪表板工具，与Prometheus配合使用

日志收集：

日志收集的方案很多，比如elk

elasticsearch：分布式搜索和分析引擎，用于存储和索引大量的日志数据

logstash：收集，过滤，转发日志数据的工具

kibana：用于日志数据可视化和分析的工具。

es提供日志存储和检索功能，logstash负责将日志收集到es，kibana负责将日志数据可视化分析。

流程：

1.在每个微服务中配置日志输出，将微服务的日志输出到标准输出studio或日志文件

2.使用logstash收集日志：配置logstash收集器，通过配置输入插件监听微服务的日志输出，并进行过滤和处理

3.将日志文件发送到elasticsearch：配置logstash的输出插件，将经过处理的日志数据发送到elasticsearch进行存储和索引

4.使用kibana进行可视化分析，通过Kibana连接到Elasticsearch，创建仪表盘、图表和搜索查询，实时监控和分析微服务的日志数据

除了应用最广泛的ELK，还有一些其它的方案比如`Fluentd`、`Graylog`、`Loki`、`Filebeat`，一些云厂商也提供了付费方案，比如阿里云的`sls`



### 分布式

##### 分布式理论

cap原则：c一致性，a可用性，p分区容错性（分布式分区容错性一定会保证）

c数据在多个副本之间保持一致的特性

a系统提供的服务必须处于一直可用的状态，每次请求都能获取到非错的响应

p分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用的服务，除非整个网络环境出现了故障



cap不可兼得

首先分布式系统，分区容错性一定要保证。

现在两个分区n1，n2，不同的分区存储d1，d2，不同的服务s1，s2

假如修改了n1的d1，再次请求落在了s2上，数据不一致。

如果保证一致性，此时d1，d2数据不一致，不能返回数据，可用性就无法保证

如果保证可用性，返回d2的数据，数据就会不一致

zookeeper保证cp，eureka保证ap，nacos可ap可cp



base理论

basically avaiable（基本可用）：假如系统出现不可预知的故障，但还是能用，只是相较于正常的系统，可能有响应时间上的损失，功能上的降级

soft state（软状态）：即允许系统中的数据存在中间状态，允许系统在多个不同节点的数据副本存在数据延时

eventually consistent（最终一致性）：不可以一直处于软状态，在一定的时间之后，应该到达一个最终的状态，保证所有副本数据一致性



##### 分布式锁

分布式锁的实现方案

mysql：创建一张锁表，数据库对字段做唯一性约束。加锁的时候，在锁表增加一条记录，释放锁的时候删除记录即可

如果有并发请求同时提交到数据库，数据库会保证只有一个请求能够得到锁。

zookeeper：zookeeper的数据节点和文件目录相似，例如有一个lock节点，在此节点下创建子节点是可以保证先后顺序的。

利用此特性，序号在节点下最小，就会获取到锁，否则就等待。

redis：

redis是实现分布式锁应用最广泛的方式。

redis执行命令是单线程的，也是利用此特性实现的分布式锁。

setnx命令，不存在则设置。加锁之后如果机器宕机，那就无法释放锁，所以要和ex命令配合使用

setnx和ex作为同一个原子操作使用。

一般使用redission客户端。



##### 分布式事务

分布式事务就是将同一个库的事务的概念扩大到多个库的事务，目的是为了保证分布式系统的一致性

分布式事务的关键是：需要记录事务在任何节点所做的任何操作，所有操作要么成功提交，要是失败回滚



分布式事务实现的方案：2pc，3pc，tcc，本地事务表，mq消息事务，最大努力通知，saga事务。

xa协议：这个协议中有三个角色：ap应用系统（服务），tm事务管理器（全局事务管理），rm资源管理器（数据库）

- 2pc：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情况决定参与者是否要提交操作还是回滚操作。
  准备阶段：事务管理器要求每个涉及到事务的数据库预提交此操作，并反映是否可以提交
  提交阶段：事务协调器要求每个数据库提交数据，或者回滚数据

  优点：尽量保证了数据的强一致，实现成本较低
  缺点：单点问题：事务管理器在第一阶段已经完成，在第二阶段正准备提交的时候事务管理器宕机，资源管理器就会阻塞，导致数据库无法使用
  			同步阻塞：在准备就绪之后，就一直处于阻塞状态，直到提交完成，释放资源
  			数据不一致：在第二阶段中，假设协调者发出来事务commit的通知，但因为网络问题，该通知仅被一部分参与者收到且提交commit操作，其余的参与者则因为没有收到通知，一直处于阻塞状态，就会产生数据的不一致。

- 3pc：为解决2pc的单点问题和同步阻塞问题。
  准备阶段：协调者向参与者发起commit请求，参与者如果可以提交就返回yes，否则返回no
  预提交阶段：协调者根据参与者在准备阶段的响应判断是否执行事务还是中断事务，参与者执行完操作之后返回ack响应，同时等待最终指令
  提交阶段：协调者根据参与者在准备阶段的响应判断是否执行事务还是中断事务：如果所有参与者返回正确的ack，则提交事务；如果一个或多个参与者错误的ack或超时，则中断；如果如果参与者无法及时接收到来自协调者的提交或者中断事务请求时，在等待超时之后，会继续进行事务提交

  可以看出，三阶段提交解决的只是两阶段提交中**单体故障**和**同步阻塞**的问题，因为加入了超时机制，这里的超时的机制作用于 **预提交阶段** 和 **提交阶段**。如果等待 **预提交请求** 超时，参与者直接回到准备阶段之前。如果等到**提交请求**超时，那参与者就会提交事务了。

  **无论是2PC还是3PC都不能保证分布式系统中的数据100%一致**。

- TCC：两阶段提交的一个变种，针对每个操作都需要一个其对应的确认和取消操作，操作成功确认操作失败取消
  Try：尝试待执行的任务
  Confirm：确认执行任务，如果try阶段执行成功，接着执行confirm阶段
  Cancer：取消待执行的任务
  TCC是业务层面的分布式事务，保证最终一致性。优点：将数据库层的二阶段提交交给应用层实现，规避了数据库2pc性能低下问题
  缺点：TCC操作功能需业务提供，开发成本高。

- 本地消息表：将分布式事务拆分为本地事务进行处理，例如在订单库新增一个消息表，将新增订单和新增消息放到一个事务里完成，然后通过轮询的方式去查询消息表，将消息推送到mq，库存服务去消费mq。。

- 订单服务中的消息有可能由于业务问题会一直重复发送，所以为了避免这种情况可以记录一下发送次数，当达到次数限制之后报警，人工接入处理；库存服务需要保证幂等，避免同一条消息被多次消费造成数据不一致。

  本地消息表这种方案实现了最终一致性，需要在业务系统里增加消息表，业务逻辑中多一次插入的DB操作，所以性能会有损耗，而且最终一致性的间隔主要有定时任务的间隔时间决定

- MQ消息事务：就是利用消息中间件将两个事务进行异步解耦。

- 消息事务依赖于消息中间件的事务消息，例如我们熟悉的RocketMQ就支持事务消息（半消息），也就是只有收到发送方确定才会正常投递的消息。

  这种方案也是实现了最终一致性，对比本地消息表实现方案，不需要再建消息表，对性能的损耗和业务的入侵更小。

- 最大努力通知：

- 最大努力通知相比实现会简单一些，适用于一些对最终一致性实时性要求没那么高的业务，比如支付通知，短信通知。

  以支付通知为例，业务系统调用支付平台进行支付，支付平台进行支付，进行操作支付之后支付平台会去同步通知业务系统支付操作是否成功，如果不成功，会一直异步重试，但是会有一个最大通知次数，如果超过这个次数后还是通知失败，就不再通知，业务系统自行调用支付平台提供一个查询接口，供业务系统进行查询支付操作是否成功。

- Seata：seata设计目标是对业务无侵入，从两阶段提交着手，进行改进，把一个分布式事务理解为包含了若干分支事务的全局事务，而全局事务的职责就是协调他所管理的分支事务达到一致性，要么一起成功提交，要么一起失败回滚。
  主要角色：TC事务协调者，管理全局性分支事务的状态，用于全局性事务的提交和回滚
                     TM事务管理者：用于开启，提交，回滚事务
                     RM资源管理器，用于分支事务上的资源管理，向TC注册分支事务，上报分支事务的状态，接收TC分支的命令来提交或回滚分支事务。

  具体流程：1.服务a的TM向TC申请一个全局事务。TC会创建一个全局事务并返回一个唯一的xid

  ​					2.服务a的RM向TC注册分支事务，将这个分支纳入xid全局事务中

  ​					3.服务a开始执行分支事务
  ​					4.服务a开始调用服务b，xid根据调用链传播

  ​					5.服务b的RM也向TC注册分支事务，纳入xid全局事务中

  ​					6.服务b开始执行分支事务

  ​					7.全局事务调用处理结束后，TM会根据有无异常情况，向TC发起全局事务的提交或回滚

  ​					8.TC协调其管辖之下的所有分支事务，决定提交或回滚

##### 分布式一致性算法

raft：raft实现过程如同选举一样，参选者需要说服大多数选民投票给他，一旦选定就跟随其操作。

raft使用心跳触发leader选举，当server启动时，初始化为follower。leader向所有follower周期性发送heartbeat。如果follower在选举超时时间内没有收到leader的heartbeat，就会等待一段随机时间后发起一次leader选举。

Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC 。结果有以下三种情况：

- 赢得了多数（超过1/2）的选票，成功选举为Leader；
- 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；
- 没有Server赢得多数的选票，Leader选举失败，等待选举时间超时（`Election Timeout`）后发起下一次选举

##### 分布式设计

幂等性：同一个接口，多次发出同一个请求，请求结果是一样的。多次调用如同一次。

问题：

1. 用户在填写某些`form表单`时，保存按钮不小心快速点了两次，表中竟然产生了两条重复的数据，只是id不一样。
2. 开发人员在项目中为了解决`接口超时`问题，通常会引入了`重试机制`。第一次请求接口超时了，请求方没能及时获取返回结果（此时有可能已经成功了），于是会对该请求重试几次，这样也会产生重复的数据。
3. mq消费者在读取消息时，有时候会读取到`重复消息`，也会产生重复的数据。

这些都是常见的幂等性问题。

在分布式系统里，只要下游服务有写（保存、更新）的操作，都有可能会产生幂等性问题。

PS:幂等和防重有些不同，防重强调的防止数据重复，幂等强调的是多次调用如一次，防重包含幂等



解决：

加乐观锁，加个version字段。

建防重表

分布式锁

token机制（推荐）：请求接口之前先获取一个唯一的token，再带着这个token去完成业务操作，服务端根据这个token是否存在来判断是否是重复的请求。



##### 分布式限流

限流算法：

计数器：第一个请求进来开始计时，接下来设定的时间内，每个请求进来就+1，超过最大请求数的请求会被拒绝，等待1s结束后计数清零。

这种方式有个很大的弊端：比如前10ms已经通过了最大的请求数，那么后面的990ms的请求只能拒绝，这种现象叫做“突刺现象”。



漏桶算法：桶底出水速度恒定，进水速度不一，当桶装满水后，溢出的部分还是会被丢弃。

实现：通过一个队列保存暂时处理不了的请求，一个线程池定期从队列里获取请求来执行。



令牌桶算法：令牌桶就是生成访问令牌的一个地方，生成的速度恒定，用户访问的时候桶里有令牌就可以访问。否则触发限流。

实现方案：guava ratelimiter实现。





### kafka

==kafka本质是日志消息代理，日志的特点就是append_only和不可变。他能带来的显而易见的好处就是强大的局限性，内存中可以抽象为buffer，内核态中他又是pagecache，磁盘上它会集中在同一磁道 从上至下，利于软件和操作系统快速写入，这也是为什么大量知名系统 不论是mysql的binlog还是redis的aof 都是使用类似的方式。 他是典型的io密集型应用，所以他并不是线程池 ，kafka的大量技术细节都在解决io性能 包括但不限于零拷贝==

##### 概念

一个分布式的支持多分区，多副本的发布订阅流处理平台。

用途：解耦，削峰，限流，异步

特点：持久化：基于磁盘持久化

​			吞吐量高，单机十万级别

​			支持消息批量处理

​			kafka基于replication多副本，ISR，选举leader

​			低延时：kafka生产和消费延时很低，毫秒级别

​			

缺点：无法弹性扩容，对partition的读写都在partition leader所在的broken，如果broken压力过大，也无法通过新增broken解决问题

​			不支持事务消息

​			扩容成本高：集群中新增的broken只会处理新topic，如果要分担老topic-partition的压力，需要手动迁移

##### kafka有哪些模式：

发布订阅：一个或多个生产者被多个消费者组中消费者订阅

点对点：一个生产者的多个分区被一个消费者组多个消费者一对一消费



##### 吞吐量高，处理速度快

零拷贝：实现了零拷贝快速移动数据，避免了内核切换

消息压缩，分批发送，批处理可以进行有效的数据压缩，并减少i/o延迟

页缓存：操作系统实现的一种主要的磁盘缓存，用来减少磁盘io的操作。

顺序读写：kafka采用顺序写入磁盘的方式，避免了随机磁盘寻址的浪费，顺序写入比随机快很多。

##### 页缓存

操作系统实现的一种主要的磁盘方式，用来减少磁盘io的操作。

类似于buffer pool。一个进程准备读取磁盘上的内容时，操作系统会先查看待读取的页是否在页缓存中，如果存在直接返回，避免磁盘io

同样写入时，操作系统也会检测数据对应的页是否在页缓存中，不在，则会先在页缓存中添加相应的页，最后将数据写入对应的页，被操作过的页变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘。

##### 零拷贝

传统的io过程包括read和write的过程。

read：将数据从磁盘读取到内核缓存区中，再拷贝到用户缓冲区

write：先将数据写入到socket缓冲区，最后写入网卡设备

整个过程涉及4次内核和用户态的切换，耗时

零拷贝采用的linux的sendfile技术

sendfile从磁盘读取到内核缓冲区，就发到socket缓冲区，省去了进程切换和一次数据拷贝，性能更好

![image-20250701152347235](..\..\notes\img\middleware\kafka\零拷贝.png)

##### kafka的三种语义

至少一次 at least once：可能会数据重复消费

设置enable.auto.commit为false，禁用自动提交，消息处理完后手动consumer，commitsync提交offset。

有可能消息处理完后，还没提交offset，消费者挂了，再次重启重新消费提交。



至多一次 at-most-once：可能会丢失数据

设置enable.auto.commit为true，开启自动提交，auto.commit.interval.ms设置为一个较低的时间范围。

kafka会有一个独立的线程，负责按照时间间隔提交offset

消费者的offset已经提交，但消息还没处理完，这时候程序挂了，重启时，会从上次提交的位置继续消费消息



仅一次 exactly-once：可以保证数据仅被消费一次

将enable-auto-commit设置为false，禁用自动提交

使用consumer-seek（topicpartition，offset）来指定offset

在处理消息的时候保存每个消息的offset

以原子事务的方式保存offset和处理消息的结果，这个时候相当于自己保存offset信息了，把offset和具体的数据绑定到一块，数据真正处理成功的时 候才会保存offset信息。这样就可以保证数据仅被处理一次了。（也就是禁用自动提交，指定偏移量消费，处理消息时，以原子事务的方式保存处理的结果和offset）

- 1 幂等性保证producer单会话单分区消息的投递精准一次；(消费了就标识一下，业务方自己做好去重)
- 2 事务保证跨多分区的写入是原子的；

##### kafka生产者

生产者的消息先被写入分区中的缓冲区中，然后分批次发送给broker

异步发送消息的同时，能够对异常情况进行处理，生产者提供了callback

分区策略：顺序轮询，随机，key-ordering

key可能是uid或者订单id，将同一标志位的所有消息都发送到同一分区，这样可以保证一个分区内的消息有序。
Kafka 中每条消息都会有自己的key，一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略。
其他分区策略。如：基于地理位置的分区策略。

##### kafka broker

为啥要分区：实现负载均衡，水平扩展

kafka可以将主题划分为多个分区，根据分区规则选择把消息存储到哪个分区中，分区规则设置合理，所有的消息会被均匀的分布到不同的分区，可以实现负载均衡水平扩展，多个订阅者可以从一个或多个分区中同时消费数据，以支撑海量数据处理能力

broker如何分配分区的：

- 在broker间平均分布分区副本;
  假设有6个broker，打算创建一个包含10个分区的Topic，复制系数为3，那么Kafka就会有30个分区副本，它可以被分配给这6个broker，这样的话，每个broker可以有5个副本。
- 要确保每个分区的每个副本分布在不同的broker上面;
  假设Leader分区0会在broker1上面，Leader分区1会在broker2上面，Leder分区2会在broker3上面。
  接下来会分配跟随者副本。如果分区0的第一个Follower在broker2上面，第二个Follower在broker3上面。
  分区1的第一个Follower在broker3上面，第二个Follower在broker4上面。

##### 顺序性

如何保证顺序性：可以保证同一个分区里的消息是有序的，也就是发送到同一个partition是有顺序的

kafka多个分区，如何保证消息的顺序性：发消息的时候执行partitionkey，kafka对其进行hash计算，根据计算结果决定放入哪个partition。这样partition key计算结果相同的消息会放在同一个partition。此时，partition数量仍然可以设置多个，提升topic的整体吞吐量。

分区和消费者数量最好相等，不要让消费者的数量大于主题分区的数量，多余的消费者会被闲置。

Kafka 有四种主流的分区分配策略： Range（按顺序） 、 RoundRobin（轮询排序） 、 Sticky 、 CooperativeSticky 。

可以通过配置参数 partition.assignment.strategy ，修改分区的分配策略。默认策略是 Range + CooperativeSticky 。 Kafka 可以同时使用 多个分区分配策略



kafka的偏移量：消费者每次消费的时候都会记录消费的物理偏移量的位置，等着下次消费，接着上次位置继续消费。

**kafka出现消息积压，有哪些原因？？怎么解决？如何提高Kafka的消费速度？**

出现积压，可能是消费的速度太慢

扩充消费者，增加消费者的数量。

使用多线程消费，提高消费速度

扩大分区。一个分区只能被消费者群组中的一个消费者消费。消费者扩大，分区最好多随之扩大。



##### 重平衡

分区的所有权从一个消费者转移到其他消费者的行为称为重平衡

新加入群组的消费者分摊了之前消费者的部分分区消息，或者消费者组的某个消费者挂了之后，其他消费者自动重新分配订阅主题分区

是实现高可用，伸缩性的重要手段

消费者通过向Kafka Broker发送心跳来维护自己是消费者组的一员并确认其拥有的分区。对于不同的消费群体来说，其组织协调者可以是不同的。只要消费者定期发送心跳，就会认为消费者是存活的并处理其分区中的消息。当消费者检索记录或者提交它所消费的记录时就会发送心跳。
如果过了一段时间 Kafka 停止发送心跳了，会话（Session）就会过期，组织协调者就会认为这个 Consumer 已经死亡，就会触发一次重平衡。如果消费者宕机并且停止发送消息，组织协调者会等待几秒钟，确认它死亡了才会触发重平衡。在这段时间里，死亡的消费者将不处理任何消息。在清理消费者时，消费者将通知协调者它要离开群组，组织协调者会触发一次重平衡，尽量降低处理停顿

**讲一下重平衡的 触发条件。哪些场景下会发生重平衡？**

1.组成员数量发生变化

2.订阅主题数量发生变化

3.订阅主题的分区数发生变化



##### 消费失败

先重试几次，如果重试还是不成功，可以根据业务选择：

放入死信队列（其他topic即可），不断重试

记录到一张表里，同时发送告警信息给开发人员

如果是不重要的信息，直接丢弃



##### 消息丢失

**讲一下Kafka的ack机制。**
acks 参数指定了要有多少个分区副本接收消息，生产者才认为消息是写入成功的。此参数对消息丢失的影响较大。
如果 acks = 0，就表示生产者也不知道自己产生的消息是否被服务器接收了，它才知道它写成功了。如果发送的途中产生了错误，生产者也不知道，它也比较懵逼，因为没有返回任何消息。这就类似于 UDP 的运输层协议，只管发，服务器接受不接受它也不关心。

如果 acks = 1，只要集群的 Leader 接收到消息，就会给生产者返回一条消息，告诉它写入成功。如果发送途中造成了网络异常或者 Leader 还没选举出来等其他情况导致消息写入失败，生产者会受到错误消息，这时候生产者往往会再次重发数据。因为消息的发送也分为 同步 和 异步，Kafka 为了保证消息的高效传输会决定是同步发送还是异步发送。如果让客户端等待服务器的响应（通过调用 Future 中的 get() 方法），显然会增加延迟，如果客户端使用回调，就会解决这个问题。

如果 acks = all，这种情况下是只有当所有参与复制的节点都收到消息时，生产者才会接收到一个来自服务器的消息。不过，它的延迟比 acks =1 时更高，因为我们要等待不只一个服务器节点接收消息。

**==Kafka如何避免消息丢失？如何保证消息的可靠性传输？==**‘

需要生产者和消费者共同配合

1.生产者：生产者调用send发送之后，可以因为网络问题并没有发送出去。所以要采用获取回调函数的形式，获取回调结果

发送失败重新发送，设置producer的retries（重试次数）为3，可以设置大一点，发送失败之后重新发送

2.消费者：消费者拉取到消息后会自动提交offset，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。
手动关闭闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。

3.kafka：加入leader所在的broker挂掉，那么就要从follower中重新选举出一个leader，但是follower的数据还没有被leader同步的话，会造成消息丢失。

可以设置ack=all

设置副本因子：replication-factory>=3

设置最小同步副本数：min-insync-replicas>=2

对于一个包含3个副本的主题，如果min.insync.replicas设置为2，那么至少要存在两个同步副本才能向分区写入数据。
如果2个副本不可用，那么broker就会停止接受生产者的请求，尝试发送数据的生产者会收到异常。



**抛开MQ自身机制，如何做到高可用，不丢失，不重复**

从生产者，消费者，mq自身存储考虑：

主要还是采用本地消息表： 

生产者：发送消息和本地的业务操作绑定成一个原子操作；除了更新业务表，也把要发送的消息内容和状态写入到一个独立的消息表中；然后通过定时任务扫表，发送到MQ，发送失败重新发送

出于性能考虑，可以在消息发出后，写入到历史表，让主表保持轻量，也可以分库分表；对于定时任务扫表会延时问题，可以采用“同步+异步”；业务事务提交后，同步调用MQ的发送接口，发送成功，更新消息表状态，失败定时任务扫表重新发送。

消费端主要做好ack和幂等：幂等主要是消费端做好去重，消费消息时保存消息唯一标志，记录到消费表，下次消费之前先判断

ack主要是消费成功之后，手动提交偏移量或者调用api向MQ发送ack；

最后的兜底操作是“对账”：本地消息表与消费表比对，如果某条消息在上游显示发送成功，却没有消费记录；就将这条消息重试或者人工干预。









**Kafka写入的数据如何保证不丢失？kafka的数据写到主节点后，还没来得及复制，就挂掉了，那数据会丢失么？**

所以如果要让写入Kafka的数据不丢失，你需要要求几点：
(1)每个Partition都至少得有1个Follower在ISR列表里，跟上了Leader的数据同步。
最小同步副本数 min.insync.replicas
最小同步副本数, 表示的是 ISR 列表里面最小的同步副本个数,默认是=1。
这个配置再加上 acks=-1/all 可以设置高可靠性了。
特别需要注意：这个配置是用来设置同步副本个数的下限的, 并不是只有 min.insync.replicas 个副本同步成功就返回ack。
只要你acks=-1/all 就意味着你ISR里面的副本必须都要同步成功。
(2)每次写入数据的时候，都要求至少写入Partition Leader成功，同时还有至少一个ISR里的Follower也写入成功，才算这个写入是成功了。
(3)如果不满足上述两个条件，那就一直写入失败，让生产系统不停的尝试重试，直到满足上述两个条件，然后才能认为写入成功
按照上述思路去配置相应的参数，才能保证写入Kafka的数据不会丢失。

==需要保证，每次写数据，必须是leader和follower都写成功了，才能算是写成功，保证一条数据必须有两个以上的副本。==
这个时候万一leader宕机，就可以切换到那个follower上去，那么Follower上是有刚写入的数据的，此时数据就不会丢失了。



##### 可靠性，副本

多副本，ISR机制

kafka主要通过ISR机制保证消息可靠性，ISR（in sync replicas）是kafka动态维护的一组副本，在ISR中有成员存活时，只有这个组的成员才可以成为leader，内部保存的为每次提交信息时必须要同步的副本，每当leader挂掉时，在ISR集合中选举出follower作为leader，当ISR中副本被认为挂掉时，会被剔除ISR，重新同步leader的消息后，才会重新进入ISR。

副本机制：

AR：AR副本集合 (Assigned Replicas)：分区Partition中的所有Replica组成AR副本集合。

ISR：所有与Leader副本能保持一定程度同步的Replica组成ISR副本集合，其中也包括 Leader副本

OSR：与Leader副本同步滞后过多的Replica组成OSR副本集合。

kafka不是读写分离：在kafka中一个topic的每个分区都有若干个副本，分为leader和follower，follower副本不对外提供服务，所有的读写请求都必须先发往leader副本所在的broker，由broker负责处理，follower做的只是从leader副本异步拉取信息，并写入自己的提交日志里，	实现与leader的同步。

**HW**：即高水位，标识着一个特定消息偏移量offset，消费者只能拉取这个水位offset之前的消息。

**LEO**：日志末端位移，代表日志文件中下一条待写入消息的offset，这个offset实际上没有消息的，不管是leader副本还是follower副本，都有这个值。

**Kafka怎么保证一致性**

定义：若某条消息对client可见，那么即使leader挂了，在新leader上数据依然可以被读到。

HW-HighWaterMark: client可以从Leader读到的最大msg offset，即对外可见的最大offset， HW=max(replica.offset)
对于Leader新收到的msg，client不能立刻消费，Leader会等待该消息被所有ISR中的replica同步后，更新HW，此时该消息才能被client消费，这样就保证了如果Leader fail，该消息仍然可以从新选举的Leader中获取。
对于来自内部Broker的读取请求，没有HW的限制。同时，Follower也会维护一份自己的HW，Folloer.HW = min(Leader.HW, Follower.offset)

##### 重复消费

一般情况下都是未正常提交offset导致，比如网络异常，消费者宕机.

将kafka消费者的配置enable-auto-commit设为false，禁止kafka自动提交offset，避免提交失败重复消费，

将消息的唯一标识保存起来，每次消费进行重新判断。

##### 消息pull push

生产者是push，消费者是pull。

push，即时性，可以在broker获取消息后马上送达消费者

pull模式可以根据comsumer的消费能力以适当的速率消费消息

消费者可以自行决定消费的速率，不足之处在于，如果kafka没有数据，消费者可能会一直轮询，一直返回空数据，针对这一点，kafka的消费者在消费数据时会传入一个时常参数timeout，如果没有数据可供消费，consumer会等待一段时间再返回。

##### 低延时，高吞吐

对于producer端：希望消息可以尽快发送出去，必须设置linger-ms=0，同时关闭压缩，另外设置acks=1，减少副本同步时间

对于consumer端，之保持fetch-min-bytes=1，即broker端只要有能返回的数据，就立即返回给consumer，减少延时。

linger.ms：表示批次缓存时间，如果数据迟迟未达到batch.size，sender 等待 linger.ms 之后就会发送数据。单位 ms，默认值是 0，意思就是消息必须立即被发送。
如果设置的太短，会导致频繁网络请求，吞吐量下降；
如果设置的太长，会导致一条消息需要等待很久才能被发送出去，增加网络延时。
所以适当增加会提高吞吐量，建议10~100毫秒。
fetch.min.bytes：表示只要 Broker 端积攒了多少数据，就可以返回给 Consumer 端。默认值1字节，适当增加该值为1kb或者更多



##### 存储

kafka使用日志文件的方式保存生产者和发送者的消息，每条消息都有一个offset值表示它在分区的偏移量。

kafka中一般存储的海量的消息数据，为了避免日志文件过大，一个分片并不是对应磁盘上一个日志文件，而是对应磁盘上一个目录，

特点：kafka把主题中一个分区划分成多个分段的小文件段，通过多个小文件段，可以容易根据偏移量查找消息，定期清除和删除已经完成的数据文件，减少磁盘容量的占用。

kafka将消息追加的操作逻辑变为日志数据文件的顺序写入，极大提高磁盘io性能



kafka集群中leader选举：kafka在zookeeper上针对每个topic都维护了一个ISR的集合，集合的增删kafka都会记录该记录，如果分区leader不可用，kafka就会在集合中选择一个副本作为leader。

zookeeper作用：主要用来集群元数据管理，集群协调工作，在每个kafka服务器启动的时候去连接并将自己注册到zookeeper，类似注册中心

kafka2.8版本开始移除zookeeper：

集群运维层面：kafka本身是一个分布式系统，如果还需要重度依赖zookeeper，集群运维成本和集群复杂度都很高。

集群性能层面：zookeeper架构涉及并不适合这种高频的读写更新操作，由于之前提交offset的操作都在zookeeper里面，这样的话会严重影响zookeeper集群性能。



### mybatis

##### 一级缓存 vs 二级缓存

\1. **一级缓存是 SqlSession 级别的**，是 MyBatis 自带的缓存功能，**默认是开启的**，并且无法关闭，所以当有两个 SqlSession 执行相同的 SQL 时，就没有用到一级缓存，而是查询了两次数据库。

\2. **二级缓存是 Mapper 级别的**，只要是同一个 Mapper，无论使用多少个 SqlSession 进行操作，数据都是共享的，所以**多个 SqlSession 可以共享二级缓存**。但是 MyBatis 的二级缓存默认是关闭的，需要时可以手动开启。此外，二级缓存还可以使用第三方的缓存，例如：Ehcache。

为什么不默认开启二级缓存呢 ？ 缓存不是可以加速程序的查询性能吗 ？

MyBatis 不默认开启二级缓存的原因有以下几点：

**1. 缓存粒度过大：**因为二级缓存是一个全局缓存，可以缓存多个不同的查询结果集。默认情况下，MyBatis 是不知道哪些查询结果需要缓存，哪些查询结果不需要缓存。当开启二级缓存后，所有的查询结果都尝试使用缓存，这就可能会导致缓存的数据不准确或者不一致性。

**2. 并发性问题：**在多线程情况下，开启二级缓存，如果没有及时清空或刷新缓存，就可能会导致缓存和数据库数据不一致性问题。此处的并发性问题可以类比到 Redis 和 MySQL 数据不一致性问题 ：

**3. 内存占用问题：**开启二级缓存之后，缓存的数据需要占用大量的内存空间，如果没有合适的策略来管理缓存，可能就会导致内存占用过多的问题。

**4. 复杂性问题：**二级缓存的配置需要考虑诸多因素，例如：缓存的刷新以及缓存的清理，这都需要较好的缓存策略来处理，这就加大了开发的复杂性，并且有可能引入新的问题。

​    基于以上问题，MyBatis 选择默认关闭二级缓存，当开发人员确认某些查询可以受益于缓存时，再手动开启二级缓存来使用即可（**把主动权交给了开发人员**）。



MyBatis 中开启二级缓存需要两步操作：

1. 在 mapper 对应的 xml 中添加 <cache> 标签；
2. 在 xml 中给需要缓存的标签设置 useCache="true"。

```XML
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.example.demo.mapper.UserMapper">
    <cache/>
    <select id="getAll" resultType="UserInfo" useCache="true">
        select count(*) from userinfo;
    </select>
</mapper>
```



##### ${}  #{}

| **特性**     | **`#{}`**                                | **`${}`**                               |
| :----------- | :--------------------------------------- | :-------------------------------------- |
| **处理方式** | 占位符，预编译参数（`?`），防止 SQL 注入 | 直接替换为字符串，不防止 SQL 注入       |
| **安全性**   | 安全（自动转义）                         | 不安全（需手动过滤）                    |
| **适用场景** | 动态参数值（如 WHERE 条件、INSERT 值）   | 动态 SQL 片段（如表名、列名、ORDER BY） |
| **类型转换** | 自动添加引号（如字符串变 `'value'`）     | 原样替换，需手动处理引号                |
| **性能**     | 预编译一次，多次执行效率高               | 每次重新解析 SQL，可能影响性能          |
| **常见用途** | 用户输入、变量值                         | 动态 SQL 拼接（非用户输入部分）         |



##### 如何传递多个参数

bean传参 或 map传参，直接传对应的参数名 #{name},#{age}

顺序传参法：按顺序#{0}，#{1}

@Param("")传参



##### 实体类名与表中字段名不一致

方式一：resultMap中<result>来映射字段名和实体类属性名映射

方式二： select的时候使用别名



##### 模糊查询怎么写

使用concat('%', {name}, '%')



##### 一对一，一对多

在resultMap中使用<association>标签实现一对一，使用<collection>实现一对多



##### 获取生成的主键

新增标签中添加：keyProperty=" ID "  即可

<insert id="insert" useGeneratedKeys="true" keyProperty="userId" >



##### 常用的动态sql

foreach，where， if， choose when；

<foreach item="item" index="index" collection="list"
    open="ID in (" separator="," close=")" nullable="true">



##### mapper接口为啥不需要实现类

很明显的jdk动态代理



##### 工作原理

读取 MyBatis 配置文件——mybatis-config.xml 、加载映射文件——映射文件即 SQL 映射文件，文件中配置了操作数据库的 SQL 语句。最后生成一个配置对象。

构造会话工厂：通过 MyBatis 的环境等配置信息构建会话工厂 SqlSessionFactory。

创建会话对象：由会话工厂创建 SqlSession 对象，该对象中包含了执行 SQL 语句的所有方法。

Executor 执行器：MyBatis 底层定义了一个 Executor 接口来操作数据库，它将根据 SqlSession 传递的参数动态地生成需要执行的 SQL 语句，同时负责查询缓存的维护。

StatementHandler：数据库会话器，串联起参数映射的处理和运行结果映射的处理。

参数处理：对输入参数的类型进行处理，并预编译。

结果处理：对返回结果的类型进行处理，根据对象映射规则，返回相应的对象。



##### Mybatis是否可以映射Enum枚举类

主要实现TypeHandler

Mybatis当然可以映射枚举类，不单可以映射枚举类，Mybatis可以映射任何对象到表的一列上。映射方式为自定义一个TypeHandler，实现TypeHandler的setParameter()和getResult()接口方法。

TypeHandler有两个作用，一是完成从javaType至jdbcType的转换，二是完成jdbcType至javaType的转换，体现为setParameter()和getResult()两个方法，分别代表设置sql问号占位符参数和获取列查询结果。

##### MyBatis使用过程？生命周期？

1. 创建SqlSessionFactory 
2. 通过SqlSessionFactory创建SqlSession
3. 通过sqlsession执行数据库操作
4. 调用session.commit()提交事务
5. 调用session.close()关闭会话

生命周期：

都是使用结束（这真是废话）或者提交事务后销毁

MyBatis 的生命周期围绕其核心组件展开：

1. **`SqlSessionFactoryBuilder`**：临时用于解析配置并构建 `SqlSessionFactory`，完成后可销毁。
2. **`SqlSessionFactory`**：全局单例，负责创建 `SqlSession`，生命周期与应用一致。
3. **`SqlSession`**：每个请求或操作单独创建，线程不安全，必须及时关闭（推荐 `try-with-resources`）。
4. **Mapper 接口**：动态代理对象，由 `SqlSession` 管理，方法调用结束后自动释放。

### JUC

##### 1.为什么使用threadpoolFactory而不使用Executors的几种常见的方式创建

newFixedThreadPool  (固定数目线程的线程池) ===》阻塞队列是无界队列LinkedBlockingQueue，可能会导致OOM

newCachedThreadPool (可缓存线程的线程池) ===》 最大线程数为Integer.MAX_VALUE，即无限大，可能会因为无限创建线程，导致OOM

newSingleThreadExecutor (单线程的线程池) ===》阻塞队列是无界队列LinkedBlockingQueue，可能会导致OOM

newScheduledThreadPool (定时及周期执行的线程池) ===》 最大线程数为Integer.MAX_VALUE，即无限大，可能会因为无限创建线程，导致OOM

如果线程获取一个任务后，任务的执行时间比较长，会导致队列的任务越积越多，导致机器内存使用不停飙升，最终导致OOM。



##### 2.线程池工作原理

1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。
2. 当调用 execute() 方法添加一个任务时，线程池会做如下判断：

- 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；

- 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；

- 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；

- 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会根据拒绝策略来对应处理。

  

  拒绝策略：

  AbortPolicy ：直接抛出异常，默认使用此策略

  CallerRunsPolicy：用调用者所在的线程来执行任务

  DiscardOldestPolicy：丢弃阻塞队列里最老的任务，也就是队列里靠前的任务

  DiscardPolicy ：当前任务直接丢弃

  

##### 3.单机线程池执行断电了应该怎么处理？

我们可以对正在处理和阻塞队列的任务做事务管理或者对阻塞队列中的任务持久化处理，并且当断电或者系统崩溃，操作无法继续下去的时候，可以通过回溯日志的方式来撤销`正在处理`的已经执行成功的操作。然后重新执行整个阻塞队列。

也就是：阻塞队列持久化；正在处理任务事务控制；断电之后正在处理任务的回滚，通过日志恢复该次操作；服务器重启后阻塞队列中的数据再加载。



##### 4.能说一下线程池有几种状态吗？

**RUNNING**

- 该状态的线程池会接收新任务，并处理阻塞队列中的任务;
- 调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;
- 调用线程池的shutdownNow()方法，可以切换到STOP状态;

**SHUTDOWN**

- 该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；
- 队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;

**STOP**

- 该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；
- 线程池中执行的任务为空,进入TIDYING状态;

**TIDYING**

- 该状态表明所有的任务已经运行终止，记录的任务数量为0。
- terminated()执行完毕，进入TERMINATED状态

**TERMINATED**

- 该状态表示线程池彻底终止

- RUNNING -> SHUTDOWN：当调用了 shutdown() 后，会发生这个状态转换，这也是最重要的
- (RUNNING or SHUTDOWN) -> STOP：当调用 shutdownNow() 后，会发生这个状态转换，这下要清楚 shutDown() 和 shutDownNow() 的区别了
- SHUTDOWN -> TIDYING：当任务队列和线程池都清空后，会由 SHUTDOWN 转换为 TIDYING
- STOP -> TIDYING：当任务队列清空后，发生这个转换
- TIDYING -> TERMINATED：这个前面说了，当 terminated() 方法结束后



##### 5.线程池的线程数应该怎么配置？

线程在Java中属于稀缺资源，线程池不是越大越好也不是越小越好。任务分为计算密集型、IO密集型、混合型。

> ❝
>
> 1. 计算密集型：大部分都在用CPU跟内存，加密，逻辑操作业务处理等。
> 2. IO密集型：数据库链接，网络通讯传输等。

1. 计算密集型一般推荐线程池不要过大，一般是CPU数 + 1，+1是因为可能存在**页缺失**(就是可能存在有些数据在硬盘中需要多来一个线程将数据读入内存)。如果线程池数太大，可能会频繁的 进行线程上下文切换跟任务调度。获得当前CPU核心数代码如下：

```
Runtime.getRuntime().availableProcessors();
```

1. IO密集型：线程数适当大一点，机器的Cpu核心数*2。
2. 混合型：可以考虑根据情况将它拆分成CPU密集型和IO密集型任务，如果执行时间相差不大，拆分可以提升吞吐量，反之没有必要。

当然，实际应用中没有固定的公式，需要结合测试和监控来进行调整。

##### 6. 什么是AQS

AQS就是一个同步器，要做的事情就相当于一个锁，所以就会有两个动作：一个是获取，一个是释放。获取释放的时候该有一个东西来记住他是被用还是没被用，这个东西就是一个状态。如果锁被获取了，也就是被用了，还有很多其他的要来获取锁，总不能给全部拒绝了，这时候就需要他们排队，这里就需要一个队列。

AQS的核心思想是：通过一个volatile修饰的int属性`state`代表同步状态，例如0是无锁状态，1是上锁状态。多线程竞争资源时，通过CAS的方式来修改state，例如从0修改为1，修改成功的线程即为资源竞争成功的线程，将其设为`exclusiveOwnerThread`，也称【工作线程】，资源竞争失败的线程会被放入一个`FIFO`的队列中并挂起休眠，当`exclusiveOwnerThread`线程释放资源后，会从队列中唤醒线程继续工作，循环往复。









### Linux

##### 根据关键词查看日志 并返回关键词所在行：

_方法一：_cat 文件名 | grep “关键词”

cat log.log | grep “train”　　# 返回log.log中包含train的所有行

_方法二：_grep -i “关键词” 文件名 （与方法一效果相同，写法不同）

grep -i “train” log.log　　# 返回log.log中包含train的所有行

```
文件处理命令：ls mkdir cd pwd rmdir cp mv rm touch cat tac more less head tail ln
权限管理命令：chmod chown chgrp umask
文件搜索：find locate which where is grep
帮助命令：man whatis apropos --help help			
用户管理命令：user add passwd who w
压缩解压命令：gzip gunzip tar zip unzip bzip2 bunzip2
网络命令：write wall ping ifconfig mall last traceroute netstat setup mount
关机重启命令：shutdown
```

##### find grep more less cat tail head

```bash
find / -name 1.txt			在根目录下查找名称为1.txt的文件
find / -name 1.txt -print0|xargs -0 ls -l  -print0 打印 find命令 结果集，用 NULL 字符 ('\0')分割，而不是换行符。
find /        	在根目录下查找
find .			在当前目录下查找
find . -size +10M				基于文件大小查找
find . -name 1.txt -type d/f	基于类型查找 d目录 f文件
   
 
ps -ef | grep java          查看所有进程
    
grep 'a' 1.txt
grep -n 'a' 1.txt				显示行号
grep -rn 'a' 1.txt              有文件夹，文件夹内也能搜索到。
grep -rn 'a' -A/B 2 1.txt		查询到a后向后/前多显示两行

find . -maxDepth 3 -name '.txt' -print0| xargs -0 grep 'docker'

more 1.txt
more -3 1.txt			3行3行查看 回车键和空格键

head/tail -n 15 1.txt		显示15行（默认显示10行）

df -h			显示linux 磁盘使用情况
du -h			显示当前目录以及所有子目录的文件占用大小
du -h -d 1		只查看一级目录下的空间占用大小

```

 



















### spring

----------------------------------------------------------------------------------      spring      -----------------------------------------------------------------------------------------

##### springboot自动配置

主配置类启动，通过springbootapplication注解中的@Enableautocinfiguration加载所需的所有自动配置类，然后自动配置类生效并给spring容器中添加各种组件。@EnableAutoConfiguration其实是通过它里面的autoconfigurationpackage将主配置类所在包下所有子包里面的所有组件扫描加载到spring容器中。还通过它里面的autonconfigurationimportselect中loadfactoryNames方法，获取类路径下meta-inf/spring.factories文件，并经过一系列判断后，作为自动配置类生效到容器中，自动配置类生效后，为我们进行自动配置工作，就会给容器中添加各种组件；这些组件的属性又是从对应的properties类中获取的，这些properties类的属性又是通过@configurationproperties注解和配置文件相互绑定的，我们能配置的属性都来自这个功能的properties类。springboot在进行自动配置的时候，会先判断容器中有没有用户自己配置的（@Bean，@Component）。有的话就用用户自己配置的，没有才自动配置，如果组件可以有多个，就将用户配置和默认配置结合起来。



##### ioc aop

**ioc**：控制反转，是一种编程思想，原本是由我们自己主动创建对象，现在是由spring来创建，管理对象，我们变为被动接收对象。ioc容器实际是一个map，

map中存储着各种对象，spring启动的时候，会通过扫描配置文件，配置类，注解来加载需要被spring容器所管理的bean，然后通过反射来创建对象，放到map中。ioc默认采用无参构造来创建对象，di依赖注入是实现ioc的一种方式，主要有构造器注入，set注入。ioc底层是一个对象工厂。

**aop**：aop面向切面编程，通过预编译和运行期动态代理的方式，实现程序功能的统一维护的一种方式。程序中主要将公共业务逻辑部分（日志，安全，事务）封装成一个切面注入到目标对象中，减少系统的重复代码，提高开发效率。



##### 事务

spring事务就是通过aop切面技术，在合适的地方开启事务，接着在合适的地方提交或回滚事务，从而实现业务编程层面的操作。

事务的传播类型：事务与事务之间的交互策略。事务a调用事务b，事务b失败回滚，事务a？？？

```
@Transaction（propagation = Propagation.REQUIRED）
```

常用的有三种：REQUIRED，REQUIRED_NEW，NESTED

**REQUIRED**：（spring默认的事务）当前方法存在事务时，子方法加入该事务，此时父子共用一个事务，无论父子方法哪个发生异常回滚，整个事务都会回滚。即使父方法捕获了异常，也是会回滚。而当前方法不存在事务时，子方法新建一个事务。

**REQUIRED_NEW**：无论当前方法是否存在事务，子方法都新建一个事务，此时父子方法的事务是独立的，他们互不影响，但父方法需要注意子方法抛出的异常，避免因子方法抛出异常，导致父方法回滚。

**NESTED**：当前方法存在事务时，子方法加入嵌套事务执行。当父方法事务回滚时，子方法也会发生回滚，当子方法发生异常回滚时，父方法是否回滚取决于是否捕获了异常，如果捕获了异常，就不回滚，否则回滚。

事务失效：@Transaction注解只有作用到public方法上事务才生效

@Transaction注解的方法所在的类必须要被spring管理

同一类中没有Transaction注解的方法内部调用@Transaction注解的方法，有@Transaction注解的方法会失效

（这是由于 Spring AOP 代理的原因造成的，因为只有当 @Transactional 注解的方法在类以外被调用的时候，Spring 事务管理才生效。

另外，如果直接调用，不通过对象调用，也是会失效的。因为 Spring 事务是通过 AOP 实现的。）



##### 过滤器与拦截器

过滤器先执行，拦截器后执行。

过滤器`Filter`是在请求进入容器后，但在进入`servlet`之前进行预处理，请求结束是在`servlet`处理完以后。

拦截器 `Interceptor` 是在请求进入`servlet`后，在进入`Controller`之前进行预处理的，`Controller` 中渲染了对应的视图之后请求结束。

执行顺序：==Filter 处理中` -> `Interceptor 前置` -> `我是controller` -> `Interceptor 处理中` -> `Interceptor 处理后==

我们项目中使用过滤器，url匹配并调用其 `forward` 方法将请求转发到新的路径 `newServletPath`，不匹配的话将请求传递给链中的下一个过滤器或目标资源；

使用拦截器做权限拦截；实现HandlerInterceptor

```java
@Order(1)
@Configuration
@WebFilter(filterName = "urlFilter", urlPatterns = "/api/*")
public class UrlFilter implements Filter {

    @Value("${spring.application.name}")
    private String applicationName;

    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
        HttpServletRequest httpServletRequest = (HttpServletRequest) request;
        String servletPath = httpServletRequest.getServletPath();
        String prefix = "/api/" + applicationName;
        if (StringUtils.isNotBlank(servletPath) && servletPath.startsWith(prefix)) {
            String newServletPath = servletPath.substring(prefix.length());
            request.getRequestDispatcher(newServletPath).forward(request, response);
        } else {
            chain.doFilter(request, response);
        }
    }

    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        Filter.super.init(filterConfig);
    }

    @Override
    public void destroy() {
        Filter.super.destroy();
    }
}
```

|                    | 过滤器                                                       | 拦截器                                                       |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 出身不同           | 过滤器来自于 Servlet                                         | 基于springmvc                                                |
| 触发时机不同       | 过滤器会先执行                                               | 然后才会执行拦截器                                           |
| 实现不同           | 基于方法回调实现的                                           | 基于动态代理（底层是反射）实现的                             |
| 使用的场景不同     | 过滤器通常是用来实现通用功能过滤的，比如：敏感词过滤、字符集编码设置、响应数据压缩等功能 | 拦截器主要用来实现项目中的业务判断的，比如：登录判断、权限判断、日志记录 |
| 支持的项目类型不同 | 过滤器要依赖 Servlet 容器，它只能用在 Web 项目中             | 拦截器是 Spring 中的一个组件，因此拦截器既可以用在 Web 项目中，同时还可以用在 Application 或 Swing 程序中 |



##### 三级缓存

**只有二级缓存时的问题**

**二级缓存工作流程**

1. **开始创建ServiceA**
   - 实例化ServiceA（原始对象）
   - 将原始ServiceA放入二级缓存
   - 开始填充ServiceA的属性
2. **发现需要ServiceB**
   - 开始创建ServiceB
   - 实例化ServiceB
   - 开始填充ServiceB的属性
3. **ServiceB需要ServiceA**
   - 从二级缓存获取ServiceA的原始对象
   - 将原始对象注入到ServiceB中
4. **继续完成ServiceA的创建**
   - ServiceB创建完成，注入到ServiceA
   - 对ServiceA应用AOP代理，生成代理对象
   - 将代理对象放入一级缓存

**问题出现**

**此时系统中存在**：

- ServiceB中持有的是ServiceA的**原始对象**
- 容器中最终保存的是ServiceA的**代理对象**

**结果**：ServiceB实际使用的是未经AOP增强的原始ServiceA，而不是预期的代理对象，导致事务等AOP功能失效。

**三级缓存如何解决这个问题**

**三级缓存工作流程**

1. **开始创建ServiceA**

   - 实例化ServiceA（原始对象）

   - 将ServiceA的ObjectFactory放入三级缓存

     ```
     addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, bean));
     ```

   - 开始填充ServiceA的属性

2. **发现需要ServiceB**

   - 开始创建ServiceB
   - 实例化ServiceB
   - 开始填充ServiceB的属性

3. **ServiceB需要ServiceA**

   - 从三级缓存获取ObjectFactory
   - 执行ObjectFactory.getEarlyBeanReference()：
     - 如果需要AOP代理，此时生成代理对象
     - 否则返回原始对象
   - 将生成的代理对象放入二级缓存
   - 将这个早期引用（可能是代理对象）注入ServiceB

4. **继续完成ServiceA的创建**

   - ServiceB创建完成，注入到ServiceA
   - 如果ServiceA已经被代理过（在getEarlyBeanReference阶段），则直接使用
   - 最终对象放入一级缓存

关键区别

- **二级缓存**：过早暴露原始对象，无法处理后续的AOP代理需求
- **三级缓存**：
  - 通过ObjectFactory延迟决定是否需要创建代理
  - 保证所有依赖注入点获取到的都是同一个对象（原始对象或代理对象）
  - 通过`getEarlyBeanReference`统一处理代理逻辑



##### 2. 双亲委派机制

1. 类加载器接收到一个加载请求时，他会委派给他的父加载器，实际上是去他父加载器的缓存中去查找是否有该类，如果有就加载返回，如果没有则继续委派给父类加载，直到顶层类加载器。
2. 如果顶层类加载器也没有加载该类，则会依次向下查找子加载器的加载路径，如果有就加载返回，如果都没有，则会抛出异常。
3. 启动类加载器（BootstrapClassloader）：用C++编写，是JVM自带的类加载器；负责加载Java的核心类库。（该加载器无法直接获取）
4. 扩展类加载器（ExtClassloader）：负责加载/jre/lib/ext目录下的jar包。
5. 应用程序类加载器（AppClassloader）：负责加载java -classpath或-D java.class.path所指的目录下的类与jar包。（最常用的加载器



Synchronized和Lock的区别 Synchronized和Lock的区别
Synchronized是关键字，内置语言实现，Lock是接口。
Synchronized在线程发生异常时会自动释放锁，因此不会发生异常死锁。Lock异常时不会自动释放锁，所以需要在finally中实现释放锁。
Lock是可以中断锁，Synchronized是非中断锁，必须等待线程执行完成释放锁。
Lock可以使用读锁提高多线程读效率。



3. ##### 过滤器 和 拦截器 区别

- 原理实现上：过滤器基于回调实现，而拦截器基于动态代理。
- 控制粒度上：过滤器和拦截器都能够实现对请求的拦截功能，但是在拦截的粒度上有较大的差异，拦截器对访问控制的粒度更细。
- 使用场景上：拦截器往往用于权限检查、日志记录等，过滤器主要用于过滤请求中无效参数，安全校验。
- 依赖容器上：过滤器依赖于Servlet容器，局限于web，而拦截器依赖于Spring框架，能够使用Spring框架的资源，不仅限于web。
- 触发时机上：过滤器在Servlet前后执行，拦截器在handler前后执行，现在大多数web应用基于Spring，拦截器更细。



##### [easyexcel--解决poi大文件发生OOM问题 ](https://www.cnblogs.com/xinrong2019/p/14236327.html)

poi问题：poi解析大部分使用的是usermode模式。内存消耗较大：一个几m的文件解析可能要用到上百m内存。

easyexcel文件解压和读取是通过文件的方式，不再是poi内存方式；采用sax模式一行一行解析，并将一行的解析结果以观察者的模式通知处理；解析时抛弃了样式字体宽度等无关紧要的数据。





### JVM

[调试排错 - JVM 调优参数 | Java 全栈知识体系 (pdai.tech)](https://pdai.tech/md/java/jvm/java-jvm-param.html)

##### jvm参数

- -Xms

堆最小值

- -Xmx

堆最大堆值。-Xms与-Xmx 的单位默认字节都是以k、m做单位的。

通常这两个配置参数相等，避免每次空间不足，动态扩容带来的影响。

- -Xmn

新生代大小

- -Xss

每个线程池的堆栈大小。在jdk5以上的版本，每个线程堆栈大小为1m，jdk5以前的版本是每个线程池大小为256k。一般在相同物理内存下，如果减少－xss值会产生更大的线程数，但不同的操作系统对进程内线程数是有限制的，是不能无限生成。

- -XX:NewRatio

设置新生代与老年代比值，-XX:NewRatio=4 表示新生代与老年代所占比例为1:4 ，新生代占比整个堆的五分之一。如果设置了-Xmn的情况下，该参数是不需要在设置的。

- -XX:PermSize

设置持久代初始值，默认是物理内存的六十四分之一

- -XX:MaxPermSize

设置持久代最大值，默认是物理内存的四分之一

- -XX:MaxTenuringThreshold

新生代中对象存活次数，默认15。(若对象在eden区，经历一次MinorGC后还活着，则被移动到Survior区，年龄加1。以后，对象每次经历MinorGC，年龄都加1。达到阀值，则移入老年代)

- -XX:SurvivorRatio

Eden区与Subrvivor区大小的比值，如果设置为8，两个Subrvivor区与一个Eden区的比值为2:8，一个Survivor区占整个新生代的十分之一

- -XX:+UseFastAccessorMethods

原始类型快速优化

- -XX:+AggressiveOpts

编译速度加快

- -XX:PretenureSizeThreshold

对象超过多大值时直接在老年代中分配

```text
说明: 
整个堆大小的计算公式: JVM 堆大小 ＝ 年轻代大小＋年老代大小＋持久代大小。
增大新生代大小就会减少对应的年老代大小，设置-Xmn值对系统性能影响较大，所以如果设置新生代大小的调整，则需要严格的测试调整。而新生代是用来存放新创建的对象，大小是随着堆大小增大和减少而有相应的变化，默认值是保持堆大小的十五分之一，-Xmn参数就是设置新生代的大小，也可以通过-XX:NewRatio来设置新生代与年老代的比例，java 官方推荐配置为3:8。

新生代的特点就是内存中的对象更新速度快，在短时间内容易产生大量的无用对象，如果在这个参数时就需要考虑垃圾回收器设置参数也需要调整。推荐使用: 复制清除算法和并行收集器进行垃圾回收，而新生代的垃圾回收叫做初级回收。
StackOverflowError和OutOfMemoryException。当线程中的请求的栈的深度大于最大可用深度，就会抛出前者；若内存空间不够，无法创建新的线程，则会抛出后者。栈的大小直接决定了函数的调用最大深度，栈越大，函数嵌套可调用次数就越多。
```

**经验** :

1. Xmn用于设置新生代的大小。过小会增加Minor GC频率，过大会减小老年代的大小。一般设为整个堆空间的1/4或1/3.
2. XX:SurvivorRatio用于设置新生代中survivor空间(from/to)和eden空间的大小比例； XX:TargetSurvivorRatio表示，当经历Minor GC后，survivor空间占有量(百分比)超过它的时候，就会压缩进入老年代(当然，如果survivor空间不够，则直接进入老年代)。默认值为50%。
3. 为了性能考虑，一开始尽量将新生代对象留在新生代，避免新生的大对象直接进入老年代。因为新生对象大部分都是短期的，这就造成了老年代的内存浪费，并且回收代价也高(Full GC发生在老年代和方法区Perm).
4. 当Xms=Xmx，可以使得堆相对稳定，避免不停震荡
5. 一般来说，MaxPermSize设为64MB可以满足绝大多数的应用了。若依然出现方法区溢出，则可以设为128MB。若128MB还不能满足需求，那么就应该考虑程序优化了，减少**动态类**的产生。

##### [#](#垃圾回收) 垃圾回收

**垃圾回收算法** :

- 引用计数法: 会有循环引用的问题，古老的方法；
- Mark-Sweep: 标记清除。根可达判断，最大的问题是空间碎片(清除垃圾之后剩下不连续的内存空间)；
- Copying: 复制算法。对于短命对象来说有用，否则需要复制大量的对象，效率低。**如Java的新生代堆空间中就是使用了它(survivor空间的from和to区)；**
- Mark-Compact: 标记整理。对于老年对象来说有用，无需复制，不会产生内存碎片

**GC考虑的指标**

- 吞吐量: 应用耗时和实际耗时的比值；
- 停顿时间: 垃圾回收的时候，由于Stop the World，应用程序的所有线程会挂起，造成应用停顿。

```text
吞吐量和停顿时间是互斥的。
对于后端服务(比如后台计算任务)，吞吐量优先考虑(并行垃圾回收)；
对于前端应用，RT响应时间优先考虑，减少垃圾收集时的停顿时间，适用场景是Web系统(并发垃圾回收)
```

**回收器的JVM参数**

- -XX:+UseSerialGC

串行垃圾回收，现在基本很少使用。

- -XX:+UseParNewGC

新生代使用并行，老年代使用串行；

- -XX:+UseConcMarkSweepGC

新生代使用并行，老年代使用CMS(一般都是使用这种方式)，CMS是Concurrent Mark Sweep的缩写，并发标记清除，一看就是老年代的算法，所以，它可以作为老年代的垃圾回收器。CMS不是独占式的，它关注停顿时间

- -XX:ParallelGCThreads

指定并行的垃圾回收线程的数量，最好等于CPU数量

- -XX:+DisableExplicitGC

禁用System.gc()，因为它会触发Full GC，这是很浪费性能的，JVM会在需要GC的时候自己触发GC。

- -XX:CMSFullGCsBeforeCompaction

在多少次GC后进行内存压缩，这个是因为并行收集器不对内存空间进行压缩的，所以运行一段时间后会产生很多碎片，使得运行效率降低。

- -XX:+CMSParallelRemarkEnabled

降低标记停顿

- -XX:+UseCMSCompactAtFullCollection

在每一次Full GC时对老年代区域碎片整理，因为CMS是不会移动内存的，因此会非常容易出现碎片导致内存不够用的

- -XX:+UseCmsInitiatingOccupancyOnly

使用手动触发或者自定义触发cms 收集，同时也会禁止hostspot 自行触发CMS GC

- -XX:CMSInitiatingOccupancyFraction

使用CMS作为垃圾回收，使用70%后开始CMS收集

- -XX:CMSInitiatingPermOccupancyFraction

设置perm gen使用达到多少％比时触发垃圾回收，默认是92%

- -XX:+CMSIncrementalMode

设置为增量模式

- -XX:+CmsClassUnloadingEnabled

CMS是不会默认对永久代进行垃圾回收的，设置此参数则是开启

- -XX:+PrintGCDetails

开启详细GC日志模式，日志的格式是和所使用的算法有关

- -XX:+PrintGCDateStamps

将时间和日期也加入到GC日志中





### 项目

##### 亮点

###### 1.jvm

grafana面板监控docker容器和linux主机，可以看到在一段时间 cpu使用飙升未下降，三分钟内gc次数达到16次，jvm堆栈突增突降，jvm申请堆栈大小由2g增长到4g。（jvm堆栈申请之后不会释放，所以cpu升高之后不会下降，cpu不止jvm，包括docker容器的所有允许的程序，，但使用的堆栈会释放）

分析：两种原因：1.内存泄漏（jvm堆栈突增之后不会下降）2.创建了大对象，之后gc掉了

在我们系统中有两种可能 1.可以是接口，2.可能是定时任务

接口：通过prometheus和grafana监控可以看到接口都是正常响应

然后就根据jvm堆栈突增世间点结合gc日志的频繁gc的时间点，查看对应时间段的日志，发现问题点。一个定时任务中的一个异步任务数据库操作，数据较大。

遍历查数据库，每次查询数据量较大，且加入到list集合中，导致大对象问题。优化：优化查询，然后批量查询，处理，不再一直加到集合中



由于没有及时发现，所以没法heapdump，只能查看gc日志。

相关命令：gc工具 [gceasy](https://gceasy.io/)  [](https://gceasy.io/)

```shell
jps 查看当前进程
jstat -gc -t 1 1000 5 表示对jvm进程Id为1的进程，每个1秒统计一次gc信息，统计5次结束
jstat -gcutil  16361 1000

jstack
1）查看线程的栈信息，即JVM的当前时刻的线程快照。

2）主要用于定位线程出现长时间停顿的原因，如线程死锁、死循环、请求外部时长过长导致线程停顿的原因。

3）建议间隔一定时间采集一次，通过3-5次采集，确认是否有线程一直处于running状态，方便定位是否出现第2点的情况

用法：

jstack <PID>

jstack <PID> > test.txt   #输出到文件

jstat
1）主要用于统计堆内存、类相关和GC相关信息
2）可以时时监控资源和性能

jstat -gc <pid>

jstat -gc <pid>  2s  100  #间隔2s连续输出100次

复制代码
[root@lsy-36-70 ~]# jstat -gc 7574 2s 10
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   
149760.0 149760.0 35129.5  0.0   749056.0 746427.7 1048576.0   222899.5  129280.0 122844.9 15104.0 14076.8    152    8.696   0      0.000    8.696
149760.0 149760.0 35129.5  0.0   749056.0 746540.0 1048576.0   222899.5  129280.0 122844.9 15104.0 14076.8    152    8.696   0      0.000    8.696
149760.0 149760.0 35129.5  0.0   749056.0 746687.8 1048576.0   222899.5  129280.0 122844.9 15104.0 14076.8    152    8.696   0      0.000    8.696
149760.0 149760.0 35129.5  0.0   749056.0 746731.0 1048576.0   222899.5  129280.0 122844.9 15104.0 14076.8    152    8.696   0      0.000    8.696
149760.0 149760.0 35129.5  0.0   749056.0 746745.0 1048576.0   222899.5  129280.0 122844.9 15104.0 14076.8    152    8.696   0      0.000    8.696
149760.0 149760.0 35129.5  0.0   749056.0 746878.8 1048576.0   222899.5  129280.0 122844.9 15104.0 14076.8    152    8.696   0      0.000    8.696
149760.0 149760.0  0.0   24516.0 749056.0  3428.4  1048576.0   223104.6  129280.0 122850.1 15104.0 14076.8    153    8.720   0      0.000    8.720
149760.0 149760.0  0.0   24516.0 749056.0  3670.3  1048576.0   223104.6  129280.0 122850.1 15104.0 14076.8    153    8.720   0      0.000    8.720
149760.0 149760.0  0.0   24516.0 749056.0  3734.9  1048576.0   223104.6  129280.0 122850.1 15104.0 14076.8    153    8.720   0      0.000    8.720
149760.0 149760.0  0.0   24516.0 749056.0  3881.1  1048576.0   223104.6  129280.0 122850.1 15104.0 14076.8    153    8.720   0      0.000    8.720
复制代码
各指标描述：

S0C：年轻代中第一个survivor（幸存区）的容量 （字节 Capacity）
S1C：年轻代中第二个survivor（幸存区）的容量 (字节)
S0U：年轻代中第一个survivor（幸存区）目前已使用空间 (字节 Used)
S1U：年轻代中第二个survivor（幸存区）目前已使用空间 (字节)
EC：年轻代中Eden（伊甸园）的容量 (字节)
EU：年轻代中Eden（伊甸园）目前已使用空间 (字节)
OC：Old代的容量 (字节)
OU：Old代目前已使用空间 (字节)
MC：metaspace(元空间)的容量 (字节)
MU：metaspace(元空间)目前已使用空间 (字节)
CCSC：当前压缩类空间的容量 (字节)
CCSU：当前压缩类空间目前已使用空间 (字节)
YGC：从应用程序启动到采样时年轻代中gc次数
YGCT：从应用程序启动到采样时年轻代中gc所用时间(s)
FGC：从应用程序启动到采样时old代(全gc)gc次数
FGCT：从应用程序启动到采样时old代(全gc)gc所用时间(s)
GCT：从应用程序启动到采样时gc用的总时间(s)

jmap 
1）查看堆内存信息，包括使用的GC算法、堆配置参数和各代中堆内存使用情况，可以结合jhat使用

2）主要用于分析OOM

用法：

jmap -heap <PID>

jmap -dump:format=b,file=HeapDump <pid>  #dump出内存信息，可用内存分析工具分析情况，format=b是通过二进制的意思

例如：

1）直接查看堆内存信息

复制代码
[root@lsy-36-70 ~]# jmap -heap 7574
Attaching to process ID 7574, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 25.211-b12

using thread-local object allocation.
Parallel GC with 8 thread(s)

Heap Configuration:
   MinHeapFreeRatio         = 0
   MaxHeapFreeRatio         = 100
   MaxHeapSize              = 3183476736 (3036.0MB)
   NewSize                  = 66060288 (63.0MB)
   MaxNewSize               = 1061158912 (1012.0MB)
   OldSize                  = 133169152 (127.0MB)
   NewRatio                 = 2
   SurvivorRatio            = 8
   MetaspaceSize            = 21807104 (20.796875MB)
   CompressedClassSpaceSize = 1073741824 (1024.0MB)
   MaxMetaspaceSize         = 17592186044415 MB
   G1HeapRegionSize         = 0 (0.0MB)

Heap Usage:
PS Young Generation
Eden Space:
   capacity = 562561024 (536.5MB)
   used     = 386173616 (368.2838592529297MB)
   free     = 176387408 (168.2161407470703MB)
   68.64564012170172% used
From Space:
   capacity = 1048576 (1.0MB)
   used     = 720896 (0.6875MB)
   free     = 327680 (0.3125MB)
   68.75% used
To Space:
   capacity = 14155776 (13.5MB)
   used     = 0 (0.0MB)
   free     = 14155776 (13.5MB)
   0.0% used
PS Old Generation
   capacity = 108003328 (103.0MB)
   used     = 27321200 (26.055526733398438MB)
   free     = 80682128 (76.94447326660156MB)
   25.296627896503338% used

16408 interned Strings occupying 1561208 bytes.
复制代码
 2）dump出堆内存信息到文件

[root@lsy-36-70 ~]# jmap -dump:format=b,file=/tmp/dump01.dat 7574
Dumping heap to /tmp/dump01.dat ...
Heap dump file created
3）jhat查看，浏览器输入7000端口访问

[root@lsy-36-70 ~]# jhat -port 7000 /tmp/dump01.dat


jvm参数
-server
-Xmx6g
-Xms6g
-XX:NewRatio=1
-XX:+UseConcMarkSweepGC
-XX:MetaspaceSize=512m
-XX:MaxMetaspaceSize=512m
-XX:+PrintGCDetail
-XX:PrintGCDateStamp
-XLoggc:/expor/Logs/gc.log
-XX:+PrintTenuringDistributiom
-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=/path/to/dump.hprof
```







### web

##### 父子传参

父传子：父组件 v-bind ，子组件defineProps定义字段

子传父：子组件defineemit("aa")，父组件@aa



默认值：withdefaults





### 一些问题

##### 1.try catch会影响性能吗

会，每次进入try块，都需要解析异常表，从字节码来看会多几行执行命令。如果没有异常，性能影响很小。

如果出现异常，会创建异常对象比如IOException e. 创建对象本身会影响cpu，内存，GC。

如果异常过多，性能下降，**可以缩小异常范围**；**避免在循环中使用异常**； **合理捕获异常类型**； **能不用异常就不用异常**； **关闭资源，别自己做，使用try-catch-resource**





### 一些面试题

##### 1.见 mysql部分11-13

##### 2.varchar(50)与varchar(500)有什么区别？内存空间都一样的话，我为什么不都用varchar(500)呢？

- **内存操作（排序、JOIN、临时表）可能分配更多内存**，因为数据库引擎可能按 `VARCHAR(500)` 的最大长度预分配缓冲区。
  - 例如，`ORDER BY` 或 `GROUP BY` 一个 `VARCHAR(500)` 字段时，数据库可能按 500 字符的预估分配内存，即使实际数据很短。
  - 如果大量使用临时表（如复杂查询），可能导致内存浪费。

- **索引列如果定义为 `VARCHAR(500)`**：

  - **索引键长度可能受限**（如 MySQL InnoDB 默认限制 767字节，若使用 UTF8mb4 则 500 字符可能超过限制）。

  - **索引查询效率可能略低**，因为索引存储时会考虑最大可能长度。

  - **索引占用空间可能略大**（但实际影响通常很小）。

    虽然存储影响不大，但性能和数据规范性可能受影响，建议按业务需求选择合适的长度

  - | 影响方面     | `VARCHAR(50)` | `VARCHAR(500)`               |
    | :----------- | :------------ | :--------------------------- |
    | **存储空间** | 实际数据决定  | 实际数据决定（无差别）       |
    | **索引效率** | 更高（短键）  | 可能略低（长键）             |
    | **内存操作** | 占用更少内存  | 可能预分配更多内存           |
    | **数据约束** | 强制短数据    | 允许超长数据（需应用层校验） |

##### 3.读已提交和可重复读级别下共享锁和排它锁有什么区别？

主要体现在锁的**持有时间**和**范围**上：

| **行为**                  | **读已提交（Read Committed）** | **可重复读（Repeatable Read）**          |
| :------------------------ | :----------------------------- | :--------------------------------------- |
| **共享锁（S锁）释放时机** | 语句执行完立即释放             | 事务结束时释放                           |
| **排他锁（X锁）释放时机** | 事务结束时释放                 | 事务结束时释放                           |
| **是否解决不可重复读**    | ❌（允许其他事务修改已读数据）  | ✅（S锁持续到事务结束，阻止修改）         |
| **是否解决幻读**          | ❌（无Gap Lock）                | ✅（通过Gap Lock阻止插入新数据）          |
| **锁的粒度**              | 仅锁定实际访问的行             | 可能锁定范围（Gap Lock + Next-Key Lock） |

##### 4.父线程用synchronized对某段代码加锁，子线程内获取到锁吗？

- **锁的归属与线程无关**，而是由**锁对象**决定。
- 如果父线程持有锁（未释放），子线程尝试获取**同一把锁**时会被阻塞，直到父线程释放锁。
- 如果父线程已释放锁，子线程可以竞争获取锁。
- **父子线程之间没有锁的继承关系**，锁的竞争是公平的。

##### 5.内存泄漏咋办？怎么排查？有哪些fullGC的原因

==**内存泄漏**==：

**常见场景**

- **静态集合（如 `Map`、`List`）未清理**。
- **未关闭的资源（如 `File`、`Socket`、`Connection`）**。
- **监听器（`Listener`）未注销**。

**解决方案**

- **使用工具分析内存泄漏**：

  - `jmap -histo:live <pid>` 查看对象分布。
  - `jvisualvm` / `MAT（Eclipse Memory Analyzer）` 分析堆转储（Heap Dump）。

- **修复代码**：

  - 使用 `WeakHashMap` 替代强引用 Map。
  - 确保资源关闭（`try-with-resources`）。

  ==**如何排查 Full GC？**==

  1. **查看 GC 日志**：

     ```
     -Xloggc:/path/to/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps
     ```

  2. **使用工具监控**：

     - `jstat -gcutil <pid> 1000`（实时 GC 统计）。
     - `jcmd <pid> GC.heap_info`（堆信息）。

  3. **分析堆转储**：

     ```
     jmap -dump:format=b,file=heap.hprof <pid>
     ```
