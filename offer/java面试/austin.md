**消息推送平台承接着站内对各种类型渠道的消息下发。项目主要对用户侧的召回（营销）以及通知消息触达，也同时负责对内网的告警和通知消息发送**。

在真正面试的过程中，当面试官让你项目介绍的时候，你就可以这样答：

**1**、消息推送平台它承接着各种消息类型的推送，比如短信、邮件、小程序、微信公众号、通知栏PUSH、企业微信、钉钉等等。你可以简单理解为：只要发送消息的，就跟它脱不了关系。

**2**、发送的消息主要给两部分用户，一部分是我们站内的真实用户（比如我们给用户发短信验证码），另一部分是我们内网的消息（比如钉钉的工作提醒、群消息助手）

如果这时候面试官不打断你，你就继续跟面试官说：**要不我来给你讲下系统的架构？**



如果面试官打断了，问了别的问题，那在这就先结束了，不过，你总会**遇到机会**把你的项目架构跟面试官描述描述。

这个过程中，你可以拿上你的笔和纸给面试官**画画**，交流交流，其实就是我GitHub仓库中`README`的这个图：



| 工程模块                    | **作用**                                             |
| --------------------------- | ---------------------------------------------------- |
| **austin-common**           | **项目公共包：存储着项目公共常量/枚举/Bean**         |
| **austin-support**          | **项目工具包：对接中间件/组件**                      |
| **austin-cron**             | **定时任务模块：对xxl-job封装和项目定时任务逻辑**    |
| **austin-web**              | **后台管理模块：提供接口给前端调用**                 |
| **austin-service-api**      | **消息接入层接口定义模块：只有接口和必要的入参依赖** |
| **austin-service-api-impl** | **消息接入层具体实现模块：真实处理请求**             |
| **austin-handler**          | **消息处理逻辑层：消费MQ下发消息**                   |
| **austin-stream**           | **实时处理模块：利用flink实时处理下发链路数据**      |
| **austin-data-house**       | **数据仓库模块：消费MQ数据写入hive**                 |

![](\notes\images\offer\img.png)

这个过程可以这样跟面试官描述：

**1**、在消息推送平台里，我们有个接入层`api`，它是**消息的统一入口**，所有的消息推送都会经过该接入层进行处理。

**2**、使用消息推送平台的业务方可以简单分为两种角色：运营和技术。如果是技术，他会调用我在接入层暴露的接口。如果是运营，他会使用我的消息推送后台去设置定时任务推送，所以我们会有个推送后台`admin`以及定时任务模块`cron`

**3**、接入层干的事情比较简单，简单概括就是消息做简单的校验以及参数拼装后就写入到了消息队列

**4**、写到了消息队列之后，自然就有个逻辑层对消息队列的消息进行消费，在我这边叫做`handler`模块，它主要对消息做去重、夜间屏蔽等逻辑，最后就分到不同的消息类型Handler进行消息发送

**5**、消息推送平台跟普通消息下发最大的不同是我们是实现对**消息全链路追踪**的，业务方可以通过推送后台实时查看消息下发的情况，针对消息模板和用户都是OK的（比如这个用户是否接收到消息，如果没接收到，那可能是因为什么被过滤了）

**6**、所以消息推送平台会有个实时流的模块，用Flink实现的。我在消息处理的过程中**对多个关键的位置进行埋点**，在Flink对这些信息做清洗处理，写进Redis

基于这个描述，以及你画的图，面试官一般就能有个比较简单的认知了，至少这个过程中你证明了你这系统是有设计的。有可能听到一半就会被打断问细节的，也可能会听你说完全程，**但至少你要有类似这种描述**

不要上来就讲各种的实现细节，各种如何实现去重、夜间屏蔽的功能。**面试官如果感兴趣，他肯定会在后面问你的**，在这里先把系统的整体架构跟他聊一遍。

## 02、项目角色

**项目主要负责人**

不要慌，别说自己负责数据库表的设计这种，**如果你是新人，数据库表还轮不到你设计**。

## 03、项目技术栈

**SpringBoot、Flink、Redis、Apollo等**

这里把自己熟悉的技术栈拎出来讲讲，不熟悉的就隐藏起来（比如`Spring Data JPA`，你就用过，只知道它的底层实现是Hibernate，那就不要在这里了）。但如果你对`Mybatis`又很了解，你就可以把`Mybatis`加上（反正面试官又看不到代码，你说`Mybatis` 那就是`Mybatis`）

注意的是：这里写的技术栈，自己是要**有点墨水**的（很容易就被问到），为什么使用XXX而不使用XXX啊？当时是怎么考量的。

**补充**：

- docker(容器技术，快速部署中间件)
- Spring Boot(快速部署环境)
- Guava(安全工具类)
- hutool(便捷开发工具类)
- OkHttp(由于使用了腾讯sdk，所以暂时在代码中没有使用http调用，如果以后接入了其他厂商的服务，可能会使用http进行调用而不用各个厂商提供的sdk)
- Logback(日志)
- MySQL(数据库)
- Apache Kafka(消息队列，抗压削峰)
- Redis(NoSQL，设置唯一key，消息去重)
- Apollo(分布式配置中心，统一配置，动态变化，白名单过滤，降低系统维护难度)
- logRecord(配置注解即可打印日志，非侵入式开发)
- XXL-JOB(分布式定时任务调度，用来设置一些消息的定时推送)



## 04、系统设计亮点

**1**、全类型渠道消息的生命周期链路追踪：在每个关键处理的阶段上进行埋点，将点位收集到Kafka，Flink统一清洗处理。实时写入Redis

**2**、消息资源隔离：不同的渠道不同的消息类型互不影响并且利用动态线程池可配置化地对消费能力进行调控

**3**、拥有完备的消息管理平台基础建设：对系统和应用资源有完整的监控和告警体系、消息模板工单审核、各种消息模板的素材管理等等

作为一个平台，我理解下应该关注的是着**可用性**、**可扩展性**以及**平台能力**。

这里写出的项目亮点可能**后续还会增改**，但这以上几点我感觉都是可以拉出来跟面试官聊聊这其中的实现过程的（特别是第一点和第二点）

在简历上我建议不要写太多技术上的细节，这个系统核心功能简单可能面试官能get到，但如果是业务系统，面试官就不知道你在写什么了。如果面试官感兴趣，是会问你技术细节的，到时候再好好吹就行啦。

## 05、总结

**项目描述**：消息推送平台承接着站内对各种类型渠道的消息下发，每天承载亿级流量推送。项目主要对用户侧的召回（营销）以及通知消息触达，也同时负责对内网的告警和通知消息发送。

**项目角色**：项目主要负责人

**项目技术栈**：SpringBoot、Flink、Redis、Apollo等

**系统设计亮点**：

- 全类型渠道消息的生命周期链路追踪：在每个关键处理的阶段上进行埋点，将点位收集到Kafka，Flink统一清洗处理。实时数据写入Redis

- 消息资源隔离：不同的渠道不同的消息类型互不影响并且利用线程池提高消费性能

- 消息去重：对消息进行频次和内容去重

  **流程**：1.web层+send 信息（参数SendRequest）  

  2. api层+send（参数SendRequest）

     1. api-impl层+send（sendRequest组装成sendtaskModel ==》 sendTaskModel组装成processContext ==》前置检查 ==》责任链 ==》 
  
        kafka、rabibtmq 发送信息）
  
  3. handler层kafka接受消息 ==》  路由到线程池处理消息（丢弃+屏蔽+去重+路由到发送渠道发送消息）
  
  4. 限流后发送消息
  
  5. 实时收集点位，写入redis



**补充**：**业务解决方案**

- 多个短信接口供应商解耦与多种消息发送方式解耦：

  > `austin-handler` 使用***适配器模式***，定义通用接口，可以在不更改原有代码的情况下拓展业务渠道，为了信息发送不局限于短信，使用了***适配器模式***配合***组合模式***定义通用的消息处理接口进行业务拓展

- 不同渠道与种类消息实现消费分离：

  描述：api消息接入层接收到请求后，将请求发往kafka，主题为topic，消息逻辑处理模块监听来自这个topic的消息，在单topic单group情况下，如果某个渠道的发送接口存在异常，超时，消息就会堵住，因为他们使用同一个消费者消费同一个topic的消息。目前采用的是单topic多group的方式解决这个问题，消费是隔离的，生产的topic是共享的。消费端使用@kafkalistener修饰方法，@kafkalistener传值是spring el表达式和读取某个配置，但我们的目的是多个group消费同一个topic，总不能给每个group定义个消费方法。最终还是翻看spring文档，找到了方案。使用kafka的***AnnotationBeanPostProcessor***动态地指定了Receiver的groupId。

  > 总体来说就是`handler消息逻辑处理模块`使用kafka作为消息队列， kafka多个group之间消费是分离的，每个group都会接受到来自同一个topic的相同消息，所以接收到消息后会进行判断，只消费属于自己的消息；在代码中使用了kafka的***AnnotationBeanPostProcessor***动态地指定了Receiver的groupId，并且使用spring的@Header注解作为消费方法的入参，以便Receiver进行对消息是否属于自己管辖的判断（使用groupId和消息中带有的groupId对比）

- 消息高性能消费：

  > `handler` 定义一个***工厂模式***方法，使用map，消费渠道作为key，线程池作为value，实现不同的消费渠道使用不同的线程池，因为线程池需要占用一定的资源，所以对于不同的线程池应当设置不同的运行参数；使用线程池进行消息消费，可以实现单个渠道的消息消费也是多线程的，这就保证了消息消费的高性能

- 不合格的消息不进入消息队列：

  > `service-api-impl` 在消息发送到消息队列之前，会进行参数校验，如果不进行参数校验直接将所有的消息都存入消息队列，终究是一种浪费，因此在消息预处理阶段，使用***责任链模式***，经历参数前置校验、参数组合、参数后置校验后再放入消息队列

- 消息去重：

  > `handler` 在发送消息前进行消息内容和发送渠道的比对，默认5分钟内同一用户收到的相同内容的消息不发送，默认一天内（24：00）每个用户最多只能收到某个渠道发送的5条消息，大于等于5条的消息进行去重，由于项目的定位是一个消息发送平台，因此不能与业务方耦合，所以使用***模板模式***在代码中***AbstractDeduplicationService***类中定义了一个抽象方法getDeduplicationKey用于业务方自行设计去重逻辑。
  >
  > **详细逻辑**：入口类：DeduplicationRuleService通过type选择去重方式构建去重参数，然后根据type选择去重处理类进行去重操作。builder接口方法build用于构建参数，抽象类abstractDeduplicationBuilder实现接口builder，初始化将去重type和当前类作为keyvalue放入map，并定义根据配置设置taskinfo参数，然后频次和内容去重实现接口方法build，调用抽象类方法各自构建去重参数。接下来根据type路由去重处理类。
  >
  > 简单来讲就是根据不同的去重类型构建不同的去重参数，也根据不同的去重类型进行不同的去重实现。最终过滤掉不合格的用户。
  >
  > **频次去重**（redis，string计数），内容去重（zset滑动窗口去重）两种最终过滤掉不符合条件的receiver。
  >
  > 频次去重：获取频次去重key列表keys（templateId+receiver+sendChannel） ==》 redis.mget(keys),返回keyvalue的inredisMap  ==》  遍历receiver列表，根据taskinfo+service+receiver获取去重key，inredismap的get方法获取value  ==》  value>param.countNum 就加入过滤的列表，否则放入readyputredismap （key为receiver，value为去重key） ==》 遍历readyputredismap，readyputredismap的value作为key，inredismap获取，放入keyvalues的map（key为去重key，value为发送次数：不为空就累加） ==》 最后pipeliensetEx。

  **内容去重**：遍历 taskinfo的receiver列表  ==》  构建去重key（receiver+templateid+content），当前时间为score，雪花算法id为scorevalue ==》

  加载执行lua脚本 DefaultRedisScript<Long>  redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource("limit.lua")));

  ==》 脚本逻辑：移除开始时间窗口之前的数据remrangeByScore ------  查看当前key的列表个数 zcard ------  否超过阈值（没有就zadd，然后expire），超过就加入过滤用户列表

  ```java
  redisUtils.execLimitLua(redisScript, Collections.singletonList(key), String.valueOf(param.getDeduplicationTime() * 1000), score, String.valueOf(param.getCountNum()), scoreValue)) 
  ```

  ```lua
  --KEYS[1]: 限流 key
  --ARGV[1]: 限流窗口,毫秒
  --ARGV[2]: 当前时间戳（作为score）
  --ARGV[3]: 阈值
  --ARGV[4]: score 对应的唯一value
  -- 1\. 移除开始时间窗口之前的数据
  redis.call('zremrangeByScore', KEYS[1], 0, ARGV[2]-ARGV[1])
  -- 2\. 统计当前元素数量
  local res = redis.call('zcard', KEYS[1])
  -- 3\. 是否超过阈值
  if (res == nil) or (res < tonumber(ARGV[3])) then
      redis.call('zadd', KEYS[1], ARGV[2], ARGV[4])
      redis.call('expire', KEYS[1], ARGV[1]/1000)
      return 0
  else
      return 1
  end
  
  ```

  

- 消息丢弃：

  > `handler` 本可以在austin-api处实现丢弃逻辑，但是可能大部分时候消息是放在在MQ中的，所以丢弃功能在austin-handler中实现

- 消息定时推送

  > `corn` 消息业务有定时推送的需求，因此项目引入了XXL-JOB分布式定时任务框架，该框架支持注册多个执行器，这样就可以将某个任务交给某一台机器处理

- 任务延时处理

  > `cron` 避免任务的大量出现影响性能，利用List定义内存中的任务队列，设置队列的大小和积压时间，通过定制化@Async注解实现异步执行任务





项目设计模式

###### 01、责任链模式

我在「消息统一接入层」那里使用了**责任链模式**，用责任链模式的好处就是**分工明确、解耦、易维护**。

**1**、将多个条件判定分散到各个的处理类上，相对于`if else`耦合性相对较低。

**2**、增加一个具体的`Handler`处理类，不会影响到`BaseHandler`的代码

责任链模式的缺点：

**1**、项目里边会有多个具体Handler类（因为每种处理都抽象为一个类，所以会有多个类）

**2**、初看代码时不太好阅读（对外只是一个`doChain`方法，而里边由多个处理类来组成，还得看相应的调用顺序）
![](images/img_1.png)

![](images/img_2.png)
责任链**配置**入口：`com.java3y.austin.service.api.impl.config.PipelineConfig`

责任链**处理**入口：`com.java3y.austin.service.api.impl.service.SendServiceImpl#send`

###### 02、模板方法模式

在austin项目代码上用到模板方法的地方还是蛮多的，比较有代表性的就是**去重**的功能。老读者可能都知道，我认为去重的功能的核心无非是**唯一Key+存储**
![](images/img_3.png)

模板方法模式要点：

1、把公共的代码抽取出来，如果该功能是不确定的，那我们将其修饰成抽象方法。

2、将几个固定步骤的功能封装到一个方法中，对外暴露这个方法，就可以非常方便调用了。

模板方法模式优点：**封装不变的部分，扩展可变的部分**。把认为是不变的部分的算法封装到父类，可变部分的交由子类来实现。

模板方法模式缺点：抽象类定义了部分抽象方法，这些抽象的方法由子类来实现，子类执行的结果影响了父类的结果(**子类对父类产生了影响**)，会带来阅读代码的难度！

我们在实际写代码的时候，一般存储和和步骤都已经确认下来了，唯一Key则可以由子类实现

![](images/img_4.png)
模板方法模式的代码1：`com.java3y.austin.handler.deduplication.service.AbstractDeduplicationService#deduplication`

模板方法模式的代码2：`com.java3y.austin.handler.handler.BaseHandler#doHandler`

###### 03、构建者模式

建造者模式更多的是**写法上**的不同，从代码结构层面上其实没有很大的区别，只是看起来会更清爽一些。我借助了**Lombok**，在类上加上一个注解`@Builder`就可以使用建造者模式的代码了，非常方便
![](images/img_5.png)

在austin里就随处可见了，各种builder**链式调用**。

###### 04、策略模式

严格意义上的策略模式是基本没什么人用的（策略模式有一个**Context上下文对象**），但如果我们说JDK线程池的设计也是**策略模式**
![](images/img_6.png)

那我可以认为的是：只要我们是面向接口编程的，那多多少少都有「策略模式」的影子

所以，austin项目使用了策略模式还是有不少的

![](images/img_7.png)
策略模式代码入口：`com.java3y.austin.handler.pending.Task#run`

###### 05、生产者消费者模式

生产者消费者模式这种「设计模式」我还看到过在面试上让手写的，像JDK线程池的实现我认为就是典型的生产者和消费者模式（将消息丢入工作队列，然后从工作队列里消费）。

我在实现延迟消费做批量的时候也实现了生产者和消费者模式，场景主要就是**我读取文件的每一行记录，积攒到一定的程度才进行消费**。

![](images/img_8.png)
生产者入口：`com.java3y.austin.cron.service.impl.TaskHandlerImpl#handle`

消费者入口：`com.java3y.austin.support.pending.AbstractLazyPending#initConsumePending`

###### 06、单例模式

单例模式和代理模式几乎都是依赖Spring环境下去玩的了，基本都不用手写。

在Spring下普通创建的对象**默认**都是单例模式，在项目里也有部分的对象是需要多例的。

比如`com.java3y.austin.handler.receiver.Receiver`（不同的渠道不同的类型开不同的消费者组）和`com.java3y.austin.cron.pending.CrowdBatchTaskPending`（数据需各自维护，线程安全问题）

![](images/img_9.png)
###### 07、代理模式

代理模式在austin下倒是没自己写过，用的小组件几乎都是基于代理模式去搞的。之前提及过的**优雅打印日志注解**，只要你去看源码，就一定会发现他们用的都是Spring的动态代理去实现的。

![](images/img_10.png)
看懂了，**就说这组件是你自己优化写的**。





## 聊些指标和系统业务/架构

我们的QPS和RT的指标都来源于日志，我们在接口被调用时打印出了**耗时**（RT）以及记录了**一条日志**（QPS）。有了这日志，我们通过GrayLog就能配置出QPS和RT的监控了。所以，我们的接口对QPS和RT都是有监控的哈

![](images/img_11.png)
在接入层部署了4台**4C8G**的机器，通过监控可以看到，日常的QPS大概百级（200左右），大促时记录的峰值是2000，RT大概在20ms。

发送接口是提供了**单发**和**批量**接口的。如果有批量推送消息的需求，我们这边是建议业务走批量接口的，这样就能一定程度上减少网络的IO，我这边所承接的QPS并不会太大。

但话又说回来，在**接口层面的压力并不大**。回到我们的系统架构上，我们有**接入层-**>**MQ**->**发送逻辑层**，接入层做的工作仅仅是组装参数，然后把消息发给MQ了。

![](images/img.png)
至于压测的话，我这边没有操作过，一般是提给测试去搞的，这块我就不太清楚了。不过系统成型了以后，发送消息这种确实不太好压，**压接入层**并没有什么太大的意义（只要MQ能顶得住，那接入层就不是问题）。

发送消息的速率瓶颈一般在**下游渠道侧**，我们调用短信/邮件等渠道都会限制速度，不同的渠道还不一样。有大概几个指标：

- 腾讯云短信3000QPS（不过我们会负载到几个短信渠道方）
- 腾讯企业邮箱大概只支持百级以下QPS（当时调高了，就会限制发送失败了，没公布出具体的QPS）
- 个推PUSH我们按发送人数（8000人/QPS）进行限制
- 而IM是我们自研的（通知类的都需要进MySQL和过风控），限制人数在600人/QPS
- ...

在消费MQ的时候，我们是每个消息渠道的每种类型都会有对应的线程池进行消费，而且这个是**动态的线程池**（不用重启发布就能调整线程池的参数）
![](images/img_12.png)

随着业务增长，当QPS真的上来了（连接数变多），我们只要**横向扩容**就好了，对于接入层来说就是无状态的。

## 总结

当我们负责一个系统时，对外需要提供接口给业务方调用，我们**是需要了解这个接口的指标以及对应的上下游**。这样在出现的问题的时候，就可以根据历史的指标去找问题，去找上下游提醒有什么风险。

面试官问到接口的性能/QPS或者压测主要是想看你**是不是真的了解你所负责的内容**，如果是搜索/推荐/流量的接口还比较好压测，但发送消息/订单/支付类似这类接口就不太好压测了。

我们能表达出对接口的指标以及相关业务的细节，那么一般面试官也不会纠着你啦（除非这个面试官也刚好做这块业务）



番外补充：

发送短信或其他消息的步骤很简单，就是对接 API 调用发送的接口。
一般项目发完就没有后续了，为什么使用 austin 平台？解决如下几个问题

1. 调用消息接口，用户收不到反馈怎么办？

需要**存储**发送的记录，还需要接口保存短信的**回执**，并在后台提供相关查询页面
![640.jpg](..\austin\images\img_13.png)

1. 某个短信渠道商挂了怎么办？

接入多个渠道商，失败了就调其他的，支持**动态分配**渠道商的流量
![640.jpg](..\austin\images\img_14.png)

1. 这个月短信花了多少钱？

将短信的发送和回执数据存到 Hive，每个月跑一次 Hive 脚本进行对账。
![640.jpg](..\austin\images\img_15.png)

1. 现在调用短信的量大吗？

监控从接口调用到消息下发整个过程的数据（主要是**接口 QPS 和下发人数**）
![640.jpg](..\austin\images\img_16.png)

1. 业务方不小心连续发了两次怎么办？

作为平台需要有这种**兜底**的功能
![640.jpg](..\austin\images\img_17.png)

1. 这条短信是谁发的？

给接入方套”模板“，有了模板才能溯源，才能做数据追踪，**模板是作为平台的基石**。

1. 经常要接入短信渠道怎么办？

上规则引擎将业务代码抽离，无需上下线即可实现功能。
![640.jpg](..\austin\images\img_18.png)